{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/Hali-creater/98c858d2ee3a2b2e879733251aa4cf8c/untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0apIy8E9LlBC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92c1b784"
      },
      "source": [
        "# Task\n",
        "Create a comprehensive AI trading assistant named ApexAMMO based on the provided requirements, including stock analysis, intelligent trading recommendations with risk management, advanced trading infrastructure with multi-broker support (starting with Alpaca), real-time data processing, and a conceptual framework for a dashboard and monitoring. The agent should use Python, combine rule-based and predictive strategies, handle real-time data from sources like Yahoo Finance and Finnhub, and include enhanced logging and error handling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f37c65ca"
      },
      "source": [
        "## Set up the development environment\n",
        "\n",
        "### Subtask:\n",
        "Install necessary libraries and set up API keys for financial data sources and brokers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "0f11a5af",
        "outputId": "6cb4b87f-d9f5-42fd-e30c-8f9a7d9c47fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3139919925.py:29: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=end_date)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame must contain the following columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    df_with_indicators = pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-01-03 00:00:00\",\n        \"max\": \"2022-01-07 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2022-01-04 00:00:00\",\n          \"2022-01-07 00:00:00\",\n          \"2022-01-05 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.425888419884413,\n        \"min\": 168.62928771972656,\n        \"max\": 178.443115234375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          176.17840576171875,\n          168.79592895507812,\n          171.4920654296875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.078404492294238,\n        \"min\": 170.72732344673003,\n        \"max\": 179.35491668068815,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          179.35491668068815,\n          170.72732344673003,\n          176.6391804132829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.512766236287481,\n        \"min\": 167.67827048943124,\n        \"max\": 175.60977025994117,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          175.60977025994117,\n          167.67827048943124,\n          171.21755382734324\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.230907649306511,\n        \"min\": 169.3155667126804,\n        \"max\": 179.05099416209845,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          179.05099416209845,\n          169.50182008704013,\n          176.09015720859438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6548284,\n        \"min\": 86709100,\n        \"max\": 104487900,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          99310400,\n          86709100,\n          94537600\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e66c8a27-b721-4e01-9fcf-3710c08536b9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Ticker</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-01-03</th>\n",
              "      <td>178.443115</td>\n",
              "      <td>179.296076</td>\n",
              "      <td>174.227395</td>\n",
              "      <td>174.345039</td>\n",
              "      <td>104487900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-04</th>\n",
              "      <td>176.178406</td>\n",
              "      <td>179.354917</td>\n",
              "      <td>175.609770</td>\n",
              "      <td>179.050994</td>\n",
              "      <td>99310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-05</th>\n",
              "      <td>171.492065</td>\n",
              "      <td>176.639180</td>\n",
              "      <td>171.217554</td>\n",
              "      <td>176.090157</td>\n",
              "      <td>94537600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-06</th>\n",
              "      <td>168.629288</td>\n",
              "      <td>171.864620</td>\n",
              "      <td>168.276342</td>\n",
              "      <td>169.315567</td>\n",
              "      <td>96904000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-07</th>\n",
              "      <td>168.795929</td>\n",
              "      <td>170.727323</td>\n",
              "      <td>167.678270</td>\n",
              "      <td>169.501820</td>\n",
              "      <td>86709100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e66c8a27-b721-4e01-9fcf-3710c08536b9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e66c8a27-b721-4e01-9fcf-3710c08536b9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e66c8a27-b721-4e01-9fcf-3710c08536b9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-2c34c44b-0ba8-4b0b-8324-e0f3b08cdec3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2c34c44b-0ba8-4b0b-8324-e0f3b08cdec3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-2c34c44b-0ba8-4b0b-8324-e0f3b08cdec3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Ticker            AAPL        AAPL        AAPL        AAPL       AAPL\n",
              "Date                                                                 \n",
              "2022-01-03  178.443115  179.296076  174.227395  174.345039  104487900\n",
              "2022-01-04  176.178406  179.354917  175.609770  179.050994   99310400\n",
              "2022-01-05  171.492065  176.639180  171.217554  176.090157   94537600\n",
              "2022-01-06  168.629288  171.864620  168.276342  169.315567   96904000\n",
              "2022-01-07  168.795929  170.727323  167.678270  169.501820   86709100"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Assuming fetch_historical_data and calculate_technical_indicators functions are defined in previous cells\n",
        "\n",
        "# Fetch historical data\n",
        "ticker = \"AAPL\"  # Example ticker\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "historical_data = fetch_historical_data(ticker, start_date, end_date)\n",
        "\n",
        "if historical_data is not None and not historical_data.empty:\n",
        "    logger.info(f\"Successfully fetched historical data for {ticker}.\")\n",
        "    # Calculate technical indicators\n",
        "    # The calculate_technical_indicators function should now handle the MultiIndex\n",
        "    df_with_indicators = calculate_technical_indicators(historical_data.copy())\n",
        "\n",
        "    if not df_with_indicators.empty:\n",
        "        logger.info(\"Technical indicators calculated.\")\n",
        "        display(df_with_indicators.head())\n",
        "    else:\n",
        "        logger.error(\"Failed to calculate technical indicators.\")\n",
        "        df_with_indicators = pd.DataFrame() # Ensure df_with_indicators is an empty DataFrame if calculation fails\n",
        "\n",
        "else:\n",
        "    logger.error(\"Failed to fetch historical data. Cannot proceed with technical analysis and ML model training.\")\n",
        "    df_with_indicators = pd.DataFrame() # Ensure df_with_indicators is an empty DataFrame if fetching fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "2e0f1335",
        "outputId": "f4de9af0-6cd2-4e43-eeff-154fd3e9daab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3139919925.py:29: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=end_date)\n",
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame must contain the following columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    df_with_indicators = pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-01-03 00:00:00\",\n        \"max\": \"2022-01-07 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2022-01-04 00:00:00\",\n          \"2022-01-07 00:00:00\",\n          \"2022-01-05 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.425888419884413,\n        \"min\": 168.62928771972656,\n        \"max\": 178.443115234375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          176.17840576171875,\n          168.79592895507812,\n          171.4920654296875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.078404492294238,\n        \"min\": 170.72732344673003,\n        \"max\": 179.35491668068815,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          179.35491668068815,\n          170.72732344673003,\n          176.6391804132829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.512766236287481,\n        \"min\": 167.67827048943124,\n        \"max\": 175.60977025994117,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          175.60977025994117,\n          167.67827048943124,\n          171.21755382734324\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.230907649306511,\n        \"min\": 169.3155667126804,\n        \"max\": 179.05099416209845,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          179.05099416209845,\n          169.50182008704013,\n          176.09015720859438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6548284,\n        \"min\": 86709100,\n        \"max\": 104487900,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          99310400,\n          86709100,\n          94537600\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f46d0041-5bbd-4fbb-a3b5-e10fbb6e8b0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Ticker</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-01-03</th>\n",
              "      <td>178.443115</td>\n",
              "      <td>179.296076</td>\n",
              "      <td>174.227395</td>\n",
              "      <td>174.345039</td>\n",
              "      <td>104487900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-04</th>\n",
              "      <td>176.178406</td>\n",
              "      <td>179.354917</td>\n",
              "      <td>175.609770</td>\n",
              "      <td>179.050994</td>\n",
              "      <td>99310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-05</th>\n",
              "      <td>171.492065</td>\n",
              "      <td>176.639180</td>\n",
              "      <td>171.217554</td>\n",
              "      <td>176.090157</td>\n",
              "      <td>94537600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-06</th>\n",
              "      <td>168.629288</td>\n",
              "      <td>171.864620</td>\n",
              "      <td>168.276342</td>\n",
              "      <td>169.315567</td>\n",
              "      <td>96904000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-07</th>\n",
              "      <td>168.795929</td>\n",
              "      <td>170.727323</td>\n",
              "      <td>167.678270</td>\n",
              "      <td>169.501820</td>\n",
              "      <td>86709100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f46d0041-5bbd-4fbb-a3b5-e10fbb6e8b0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f46d0041-5bbd-4fbb-a3b5-e10fbb6e8b0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f46d0041-5bbd-4fbb-a3b5-e10fbb6e8b0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a82b9b21-7a5f-4fd2-8b9d-8d644e7007bc\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a82b9b21-7a5f-4fd2-8b9d-8d644e7007bc')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a82b9b21-7a5f-4fd2-8b9d-8d644e7007bc button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Ticker            AAPL        AAPL        AAPL        AAPL       AAPL\n",
              "Date                                                                 \n",
              "2022-01-03  178.443115  179.296076  174.227395  174.345039  104487900\n",
              "2022-01-04  176.178406  179.354917  175.609770  179.050994   99310400\n",
              "2022-01-05  171.492065  176.639180  171.217554  176.090157   94537600\n",
              "2022-01-06  168.629288  171.864620  168.276342  169.315567   96904000\n",
              "2022-01-07  168.795929  170.727323  167.678270  169.501820   86709100"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Assuming fetch_historical_data and calculate_technical_indicators functions are defined in previous cells\n",
        "\n",
        "# Fetch historical data\n",
        "ticker = \"AAPL\"  # Example ticker\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "historical_data = fetch_historical_data(ticker, start_date, end_date)\n",
        "\n",
        "if historical_data is not None and not historical_data.empty:\n",
        "    logger.info(f\"Successfully fetched historical data for {ticker}.\")\n",
        "    # Calculate technical indicators\n",
        "    # The calculate_technical_indicators function should now handle the MultiIndex\n",
        "    df_with_indicators = calculate_technical_indicators(historical_data.copy())\n",
        "\n",
        "    if not df_with_indicators.empty:\n",
        "        logger.info(\"Technical indicators calculated.\")\n",
        "        display(df_with_indicators.head())\n",
        "    else:\n",
        "        logger.error(\"Failed to calculate technical indicators.\")\n",
        "        df_with_indicators = pd.DataFrame() # Ensure df_with_indicators is an empty DataFrame if calculation fails\n",
        "\n",
        "else:\n",
        "    logger.error(\"Failed to fetch historical data. Cannot proceed with technical analysis and ML model training.\")\n",
        "    df_with_indicators = pd.DataFrame() # Ensure df_with_indicators is an empty DataFrame if fetching fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "71f90e99",
        "outputId": "1e4e59ae-7ac9-41ea-95b3-47a691e737c3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3139919925.py:29: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame must contain the following columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    df_with_indicators = pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-01-03 00:00:00\",\n        \"max\": \"2022-01-07 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2022-01-04 00:00:00\",\n          \"2022-01-07 00:00:00\",\n          \"2022-01-05 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.425888419884413,\n        \"min\": 168.62928771972656,\n        \"max\": 178.443115234375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          176.17840576171875,\n          168.79592895507812,\n          171.4920654296875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.078404492294238,\n        \"min\": 170.72732344673003,\n        \"max\": 179.35491668068815,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          179.35491668068815,\n          170.72732344673003,\n          176.6391804132829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.512766236287481,\n        \"min\": 167.67827048943124,\n        \"max\": 175.60977025994117,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          175.60977025994117,\n          167.67827048943124,\n          171.21755382734324\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.230907649306511,\n        \"min\": 169.3155667126804,\n        \"max\": 179.05099416209845,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          179.05099416209845,\n          169.50182008704013,\n          176.09015720859438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6548284,\n        \"min\": 86709100,\n        \"max\": 104487900,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          99310400,\n          86709100,\n          94537600\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-91f721a7-09d1-40fa-b48a-714c88fc6a74\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Ticker</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-01-03</th>\n",
              "      <td>178.443115</td>\n",
              "      <td>179.296076</td>\n",
              "      <td>174.227395</td>\n",
              "      <td>174.345039</td>\n",
              "      <td>104487900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-04</th>\n",
              "      <td>176.178406</td>\n",
              "      <td>179.354917</td>\n",
              "      <td>175.609770</td>\n",
              "      <td>179.050994</td>\n",
              "      <td>99310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-05</th>\n",
              "      <td>171.492065</td>\n",
              "      <td>176.639180</td>\n",
              "      <td>171.217554</td>\n",
              "      <td>176.090157</td>\n",
              "      <td>94537600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-06</th>\n",
              "      <td>168.629288</td>\n",
              "      <td>171.864620</td>\n",
              "      <td>168.276342</td>\n",
              "      <td>169.315567</td>\n",
              "      <td>96904000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-07</th>\n",
              "      <td>168.795929</td>\n",
              "      <td>170.727323</td>\n",
              "      <td>167.678270</td>\n",
              "      <td>169.501820</td>\n",
              "      <td>86709100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91f721a7-09d1-40fa-b48a-714c88fc6a74')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-91f721a7-09d1-40fa-b48a-714c88fc6a74 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-91f721a7-09d1-40fa-b48a-714c88fc6a74');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9d8b7eae-9755-42ff-a5e8-01aba6ff4b12\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d8b7eae-9755-42ff-a5e8-01aba6ff4b12')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9d8b7eae-9755-42ff-a5e8-01aba6ff4b12 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Ticker            AAPL        AAPL        AAPL        AAPL       AAPL\n",
              "Date                                                                 \n",
              "2022-01-03  178.443115  179.296076  174.227395  174.345039  104487900\n",
              "2022-01-04  176.178406  179.354917  175.609770  179.050994   99310400\n",
              "2022-01-05  171.492065  176.639180  171.217554  176.090157   94537600\n",
              "2022-01-06  168.629288  171.864620  168.276342  169.315567   96904000\n",
              "2022-01-07  168.795929  170.727323  167.678270  169.501820   86709100"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Assuming fetch_historical_data and calculate_technical_indicators functions are defined in previous cells\n",
        "\n",
        "# Fetch historical data\n",
        "ticker = \"AAPL\"  # Example ticker\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "historical_data = fetch_historical_data(ticker, start_date, end_date)\n",
        "\n",
        "if historical_data is not None and not historical_data.empty:\n",
        "    logger.info(f\"Successfully fetched historical data for {ticker}.\")\n",
        "    # Calculate technical indicators\n",
        "    df_with_indicators = calculate_technical_indicators(historical_data.copy())\n",
        "\n",
        "    if not df_with_indicators.empty:\n",
        "        logger.info(\"Technical indicators calculated.\")\n",
        "        display(df_with_indicators.head())\n",
        "    else:\n",
        "        logger.error(\"Failed to calculate technical indicators.\")\n",
        "        df_with_indicators = pd.DataFrame() # Ensure df_with_indicators is an empty DataFrame if calculation fails\n",
        "\n",
        "else:\n",
        "    logger.error(\"Failed to fetch historical data. Cannot proceed with technical analysis and ML model training.\")\n",
        "    df_with_indicators = pd.DataFrame() # Ensure df_with_indicators is an empty DataFrame if fetching fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "74db119f",
        "outputId": "a4d8f934-3104-4605-fe68-909188dc1898"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3139919925.py:29: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
            "  data = yf.download(ticker, start=start_date, end=end_date)\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataFrame must contain the following columns: ['Open', 'High', 'Low', 'Close', 'Volume']\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"    df_with_indicators = pd\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2022-01-03 00:00:00\",\n        \"max\": \"2022-01-07 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2022-01-04 00:00:00\",\n          \"2022-01-07 00:00:00\",\n          \"2022-01-05 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.425888419884413,\n        \"min\": 168.62928771972656,\n        \"max\": 178.443115234375,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          176.17840576171875,\n          168.79592895507812,\n          171.4920654296875\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.078404492294238,\n        \"min\": 170.72732344673003,\n        \"max\": 179.35491668068815,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          179.35491668068815,\n          170.72732344673003,\n          176.6391804132829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3.512766236287481,\n        \"min\": 167.67827048943124,\n        \"max\": 175.60977025994117,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          175.60977025994117,\n          167.67827048943124,\n          171.21755382734324\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.230907649306511,\n        \"min\": 169.3155667126804,\n        \"max\": 179.05099416209845,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          179.05099416209845,\n          169.50182008704013,\n          176.09015720859438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AAPL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6548284,\n        \"min\": 86709100,\n        \"max\": 104487900,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          99310400,\n          86709100,\n          94537600\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-e8c1e42e-ff3d-4ae5-9db4-d13d7a2fd262\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Ticker</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "      <th>AAPL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-01-03</th>\n",
              "      <td>178.443115</td>\n",
              "      <td>179.296076</td>\n",
              "      <td>174.227395</td>\n",
              "      <td>174.345039</td>\n",
              "      <td>104487900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-04</th>\n",
              "      <td>176.178406</td>\n",
              "      <td>179.354917</td>\n",
              "      <td>175.609770</td>\n",
              "      <td>179.050994</td>\n",
              "      <td>99310400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-05</th>\n",
              "      <td>171.492065</td>\n",
              "      <td>176.639180</td>\n",
              "      <td>171.217554</td>\n",
              "      <td>176.090157</td>\n",
              "      <td>94537600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-06</th>\n",
              "      <td>168.629288</td>\n",
              "      <td>171.864620</td>\n",
              "      <td>168.276342</td>\n",
              "      <td>169.315567</td>\n",
              "      <td>96904000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-01-07</th>\n",
              "      <td>168.795929</td>\n",
              "      <td>170.727323</td>\n",
              "      <td>167.678270</td>\n",
              "      <td>169.501820</td>\n",
              "      <td>86709100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8c1e42e-ff3d-4ae5-9db4-d13d7a2fd262')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8c1e42e-ff3d-4ae5-9db4-d13d7a2fd262 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8c1e42e-ff3d-4ae5-9db4-d13d7a2fd262');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-f4463e7c-ab3a-4dbc-8d59-423e1b9939ca\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f4463e7c-ab3a-4dbc-8d59-423e1b9939ca')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-f4463e7c-ab3a-4dbc-8d59-423e1b9939ca button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Ticker            AAPL        AAPL        AAPL        AAPL       AAPL\n",
              "Date                                                                 \n",
              "2022-01-03  178.443115  179.296076  174.227395  174.345039  104487900\n",
              "2022-01-04  176.178406  179.354917  175.609770  179.050994   99310400\n",
              "2022-01-05  171.492065  176.639180  171.217554  176.090157   94537600\n",
              "2022-01-06  168.629288  171.864620  168.276342  169.315567   96904000\n",
              "2022-01-07  168.795929  170.727323  167.678270  169.501820   86709100"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Assuming fetch_historical_data and calculate_technical_indicators functions are defined in previous cells\n",
        "\n",
        "# Fetch historical data\n",
        "ticker = \"AAPL\"  # Example ticker\n",
        "start_date = \"2022-01-01\"\n",
        "end_date = \"2022-12-31\"\n",
        "historical_data = fetch_historical_data(ticker, start_date, end_date)\n",
        "\n",
        "if historical_data is not None and not historical_data.empty:\n",
        "    logger.info(f\"Successfully fetched historical data for {ticker}.\")\n",
        "    # Calculate technical indicators\n",
        "    df_with_indicators = calculate_technical_indicators(historical_data.copy())\n",
        "\n",
        "    if not df_with_indicators.empty:\n",
        "        logger.info(\"Technical indicators calculated.\")\n",
        "        display(df_with_indicators.head())\n",
        "    else:\n",
        "        logger.error(\"Failed to calculate technical indicators.\")\n",
        "        df_with_indicators = pd.DataFrame() # Ensure df_with_indicators is an empty DataFrame if calculation fails\n",
        "\n",
        "else:\n",
        "    logger.error(\"Failed to fetch historical data. Cannot proceed with technical analysis and ML model training.\")\n",
        "    df_with_indicators = pd.DataFrame() # Ensure df_with_indicators is an empty DataFrame if fetching fails"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbb127ac"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to train the ML model failed because the `df_with_indicators` DataFrame was not available. This DataFrame is generated by calculating technical indicators on historical data. I will now fetch historical data using the `fetch_historical_data` function and then calculate the technical indicators using the `calculate_technical_indicators` function to create the `df_with_indicators` DataFrame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaa2350e"
      },
      "source": [
        "## Machine learning integration (Continued)\n",
        "\n",
        "### Subtask:\n",
        "Train and evaluate a machine learning model for predictive modeling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0792ba8"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the data is prepared with the target variable, I will train a RandomForestClassifier model to predict the next day's price movement. I will split the data into training and testing sets, train the model, and then evaluate its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "e19b5b4e",
        "outputId": "75762dbf-cbfc-41a3-acbd-4790e7617ed2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:ApexAMMO:DataFrame 'df_with_indicators' is not available or does not contain the 'Target' column. Cannot train ML model.\n"
          ]
        }
      ],
      "source": [
        "# Ensure df_with_indicators is available and has the 'Target' column\n",
        "if 'df_with_indicators' not in locals() or df_with_indicators.empty or 'Target' not in df_with_indicators.columns:\n",
        "    logger.error(\"DataFrame 'df_with_indicators' is not available or does not contain the 'Target' column. Cannot train ML model.\")\n",
        "else:\n",
        "    logger.info(\"Starting ML model training and evaluation.\")\n",
        "\n",
        "    # Define features (X) and target (y)\n",
        "    # Exclude 'Open', 'High', 'Low', 'Close', 'Volume', and 'Target' as features if not needed for the model\n",
        "    # Keep technical indicators as features\n",
        "    features = ['RSI_14', 'MACD_12_26_9', 'MACDH_12_26_9', 'MACDS_12_26_9', 'SMA_20', 'SMA_50']\n",
        "    # Ensure all features exist in the DataFrame and drop rows with NaN values in features or target\n",
        "    df_model = df_with_indicators.copy()\n",
        "    df_model.dropna(subset=features + ['Target'], inplace=True)\n",
        "\n",
        "\n",
        "    if df_model.empty:\n",
        "        logger.error(\"DataFrame is empty after dropping rows with missing values. Cannot train ML model.\")\n",
        "    else:\n",
        "        X = df_model[features]\n",
        "        y = df_model['Target']\n",
        "\n",
        "        # Split data into training and testing sets\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "        logger.info(f\"Data split into training ({len(X_train)} samples) and testing ({len(X_test)} samples).\")\n",
        "\n",
        "        # Initialize and train the RandomForestClassifier model\n",
        "        model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "        logger.info(\"Training RandomForestClassifier model...\")\n",
        "        model.fit(X_train, y_train)\n",
        "        logger.info(\"Model training complete.\")\n",
        "\n",
        "        # Make predictions on the test set\n",
        "        y_pred = model.predict(X_test)\n",
        "        logger.info(\"Predictions made on the test set.\")\n",
        "\n",
        "        # Evaluate the model\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "        logger.info(f\"Model Accuracy: {accuracy}\")\n",
        "        logger.info(f\"Classification Report:\\n{classification_rep}\")\n",
        "\n",
        "        print(f\"Model Accuracy: {accuracy}\")\n",
        "        print(f\"Classification Report:\\n{classification_rep}\")\n",
        "\n",
        "        # Store the trained model and features for later use\n",
        "        # You might want to save the model to a file in a real application\n",
        "        trained_ml_model = model\n",
        "        ml_model_features = features\n",
        "        logger.info(\"Trained ML model and features stored.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6067419a"
      },
      "source": [
        "## Trading infrastructure (Continued)\n",
        "\n",
        "### Subtask:\n",
        "Implement functions for order execution (placing orders, checking status, managing positions) using the Alpaca API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5d1461fe"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempts to import `alpaca_trade_api` failed. I will try reinstalling `alpaca-trade-api` and its dependency `alpha-vantage` with `force-reinstall` to resolve any potential installation issues. After successful installation and import, I will implement the core trading functions for interacting with the Alpaca API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9aa2487a",
        "outputId": "2a1dc4d3-1c0e-4086-f492-2b4176f464f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting alpaca-trade-api\n",
            "  Using cached alpaca_trade_api-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting alpha-vantage\n",
            "  Using cached alpha_vantage-3.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting pandas>=0.18.1 (from alpaca-trade-api)\n",
            "  Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (91 kB)\n",
            "Collecting numpy>=1.11.1 (from alpaca-trade-api)\n",
            "  Using cached numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
            "Collecting requests<3,>2 (from alpaca-trade-api)\n",
            "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting urllib3<2,>1.24 (from alpaca-trade-api)\n",
            "  Using cached urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "Collecting websocket-client<2,>=0.56.0 (from alpaca-trade-api)\n",
            "  Using cached websocket_client-1.9.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Collecting websockets<11,>=9.0 (from alpaca-trade-api)\n",
            "  Using cached websockets-10.4-cp312-cp312-linux_x86_64.whl\n",
            "Collecting msgpack==1.0.3 (from alpaca-trade-api)\n",
            "  Using cached msgpack-1.0.3-cp312-cp312-linux_x86_64.whl\n",
            "Collecting aiohttp<4,>=3.8.3 (from alpaca-trade-api)\n",
            "  Using cached aiohttp-3.13.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting PyYAML==6.0.1 (from alpaca-trade-api)\n",
            "  Using cached PyYAML-6.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting deprecation==2.1.0 (from alpaca-trade-api)\n",
            "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting packaging (from deprecation==2.1.0->alpaca-trade-api)\n",
            "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
            "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting aiosignal>=1.4.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
            "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting attrs>=17.3.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
            "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
            "  Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (20 kB)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
            "  Using cached multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting propcache>=0.2.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
            "  Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
            "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
            "  Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (75 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas>=0.18.1->alpaca-trade-api)\n",
            "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=0.18.1->alpaca-trade-api)\n",
            "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=0.18.1->alpaca-trade-api)\n",
            "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting charset_normalizer<4,>=2 (from requests<3,>2->alpaca-trade-api)\n",
            "  Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (37 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>2->alpaca-trade-api)\n",
            "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>2->alpaca-trade-api)\n",
            "  Using cached certifi-2025.10.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting typing-extensions>=4.2 (from aiosignal>=1.4.0->aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
            "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas>=0.18.1->alpaca-trade-api)\n",
            "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Using cached alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
            "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached PyYAML-6.0.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (724 kB)\n",
            "Using cached alpha_vantage-3.0.0-py3-none-any.whl (35 kB)\n",
            "Using cached aiohttp-3.13.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n",
            "Using cached numpy-2.3.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
            "Using cached pandas-2.3.3-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.4 MB)\n",
            "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "Using cached urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "Using cached websocket_client-1.9.0-py3-none-any.whl (82 kB)\n",
            "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
            "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
            "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
            "Using cached certifi-2025.10.5-py3-none-any.whl (163 kB)\n",
            "Using cached charset_normalizer-3.4.4-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (153 kB)\n",
            "Using cached frozenlist-1.8.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (242 kB)\n",
            "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
            "Using cached multidict-6.7.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (256 kB)\n",
            "Using cached propcache-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (221 kB)\n",
            "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "Using cached yarl-1.22.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (377 kB)\n",
            "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
            "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
            "Installing collected packages: pytz, msgpack, websockets, websocket-client, urllib3, tzdata, typing-extensions, six, PyYAML, propcache, packaging, numpy, multidict, idna, frozenlist, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, python-dateutil, deprecation, aiosignal, pandas, aiohttp, alpha-vantage, alpaca-trade-api\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.2\n",
            "    Uninstalling pytz-2025.2:\n",
            "      Successfully uninstalled pytz-2025.2\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.3\n",
            "    Uninstalling msgpack-1.0.3:\n",
            "      Successfully uninstalled msgpack-1.0.3\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 10.4\n",
            "    Uninstalling websockets-10.4:\n",
            "      Successfully uninstalled websockets-10.4\n",
            "  Attempting uninstall: websocket-client\n",
            "    Found existing installation: websocket-client 1.9.0\n",
            "    Uninstalling websocket-client-1.9.0:\n",
            "      Successfully uninstalled websocket-client-1.9.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.20\n",
            "    Uninstalling urllib3-1.26.20:\n",
            "      Successfully uninstalled urllib3-1.26.20\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.2\n",
            "    Uninstalling tzdata-2025.2:\n",
            "      Successfully uninstalled tzdata-2025.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.15.0\n",
            "    Uninstalling typing_extensions-4.15.0:\n",
            "      Successfully uninstalled typing_extensions-4.15.0\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 6.0.1\n",
            "    Uninstalling PyYAML-6.0.1:\n",
            "      Successfully uninstalled PyYAML-6.0.1\n",
            "  Attempting uninstall: propcache\n",
            "    Found existing installation: propcache 0.4.1\n",
            "    Uninstalling propcache-0.4.1:\n",
            "      Successfully uninstalled propcache-0.4.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 25.0\n",
            "    Uninstalling packaging-25.0:\n",
            "      Successfully uninstalled packaging-25.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.4\n",
            "    Uninstalling numpy-2.3.4:\n",
            "      Successfully uninstalled numpy-2.3.4\n",
            "  Attempting uninstall: multidict\n",
            "    Found existing installation: multidict 6.7.0\n",
            "    Uninstalling multidict-6.7.0:\n",
            "      Successfully uninstalled multidict-6.7.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.11\n",
            "    Uninstalling idna-3.11:\n",
            "      Successfully uninstalled idna-3.11\n",
            "  Attempting uninstall: frozenlist\n",
            "    Found existing installation: frozenlist 1.8.0\n",
            "    Uninstalling frozenlist-1.8.0:\n",
            "      Successfully uninstalled frozenlist-1.8.0\n",
            "  Attempting uninstall: charset_normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.4\n",
            "    Uninstalling charset-normalizer-3.4.4:\n",
            "      Successfully uninstalled charset-normalizer-3.4.4\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.10.5\n",
            "    Uninstalling certifi-2025.10.5:\n",
            "      Successfully uninstalled certifi-2025.10.5\n",
            "  Attempting uninstall: attrs\n",
            "    Found existing installation: attrs 25.4.0\n",
            "    Uninstalling attrs-25.4.0:\n",
            "      Successfully uninstalled attrs-25.4.0\n",
            "  Attempting uninstall: aiohappyeyeballs\n",
            "    Found existing installation: aiohappyeyeballs 2.6.1\n",
            "    Uninstalling aiohappyeyeballs-2.6.1:\n",
            "      Successfully uninstalled aiohappyeyeballs-2.6.1\n",
            "  Attempting uninstall: yarl\n",
            "    Found existing installation: yarl 1.22.0\n",
            "    Uninstalling yarl-1.22.0:\n",
            "      Successfully uninstalled yarl-1.22.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.5\n",
            "    Uninstalling requests-2.32.5:\n",
            "      Successfully uninstalled requests-2.32.5\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.9.0.post0\n",
            "    Uninstalling python-dateutil-2.9.0.post0:\n",
            "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
            "  Attempting uninstall: deprecation\n",
            "    Found existing installation: deprecation 2.1.0\n",
            "    Uninstalling deprecation-2.1.0:\n",
            "      Successfully uninstalled deprecation-2.1.0\n",
            "  Attempting uninstall: aiosignal\n",
            "    Found existing installation: aiosignal 1.4.0\n",
            "    Uninstalling aiosignal-1.4.0:\n",
            "      Successfully uninstalled aiosignal-1.4.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.3.3\n",
            "    Uninstalling pandas-2.3.3:\n",
            "      Successfully uninstalled pandas-2.3.3\n",
            "  Attempting uninstall: aiohttp\n",
            "    Found existing installation: aiohttp 3.13.1\n",
            "    Uninstalling aiohttp-3.13.1:\n",
            "      Successfully uninstalled aiohttp-3.13.1\n",
            "  Attempting uninstall: alpha-vantage\n",
            "    Found existing installation: alpha_vantage 3.0.0\n",
            "    Uninstalling alpha_vantage-3.0.0:\n",
            "      Successfully uninstalled alpha_vantage-3.0.0\n",
            "  Attempting uninstall: alpaca-trade-api\n",
            "    Found existing installation: alpaca-trade-api 3.2.0\n",
            "    Uninstalling alpaca-trade-api-3.2.0:\n",
            "      Successfully uninstalled alpaca-trade-api-3.2.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scipy 1.12.0 requires numpy<1.29.0,>=1.22.4, but you have numpy 2.3.4 which is incompatible.\n",
            "numba 0.61.2 requires numpy<2.3,>=1.24, but you have numpy 2.3.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.16.0 requires PyYAML<7.0.0,>=6.0.2, but you have pyyaml 6.0.1 which is incompatible.\n",
            "google-adk 1.16.0 requires websockets<16.0.0,>=15.0.1, but you have websockets 10.4 which is incompatible.\n",
            "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 10.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "tensorflow 2.19.0 requires numpy<2.2.0,>=1.26.0, but you have numpy 2.3.4 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "gradio-client 1.13.3 requires websockets<16.0,>=13.0, but you have websockets 10.4 which is incompatible.\n",
            "cupy-cuda12x 13.3.0 requires numpy<2.3,>=1.22, but you have numpy 2.3.4 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 2.3.4 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires websockets>=14.0, but you have websockets 10.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\n",
            "google-genai 1.44.0 requires websockets<15.1.0,>=13.0.0, but you have websockets 10.4 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed PyYAML-6.0.1 aiohappyeyeballs-2.6.1 aiohttp-3.13.1 aiosignal-1.4.0 alpaca-trade-api-3.2.0 alpha-vantage-3.0.0 attrs-25.4.0 certifi-2025.10.5 charset_normalizer-3.4.4 deprecation-2.1.0 frozenlist-1.8.0 idna-3.11 msgpack-1.0.3 multidict-6.7.0 numpy-2.3.4 packaging-25.0 pandas-2.3.3 propcache-0.4.1 python-dateutil-2.9.0.post0 pytz-2025.2 requests-2.32.5 six-1.17.0 typing-extensions-4.15.0 tzdata-2025.2 urllib3-1.26.20 websocket-client-1.9.0 websockets-10.4 yarl-1.22.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "3f0c095b337f4978b24e54314689ed15",
              "pip_warning": {
                "packages": [
                  "certifi",
                  "dateutil",
                  "idna",
                  "numpy",
                  "packaging",
                  "pandas",
                  "pytz",
                  "requests",
                  "six",
                  "tzdata",
                  "urllib3",
                  "websockets",
                  "yaml"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ImportError: cannot import name 'URL' from 'alpaca_trade_api.common' (/usr/local/lib/python3.12/dist-packages/alpaca_trade_api/common.py)\n",
            "Alpaca API functionality is unavailable due to import issues.\n",
            "Alpaca trading functions defined.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade --force-reinstall alpaca-trade-api alpha-vantage\n",
        "\n",
        "try:\n",
        "    import alpaca_trade_api as tradeapi\n",
        "    import os\n",
        "    import logging\n",
        "\n",
        "    logger = logging.getLogger('ApexAMMO')\n",
        "\n",
        "    print(\"alpaca_trade_api imported successfully.\")\n",
        "\n",
        "    # Define the functions for interacting with Alpaca API\n",
        "    # These functions were partially defined before, now adding logging and error handling\n",
        "\n",
        "    # Removed type hint -> tradeapi.REST\n",
        "    def initialize_alpaca_api():\n",
        "        \"\"\"\n",
        "        Initializes and returns an Alpaca API object with logging and error handling.\n",
        "        \"\"\"\n",
        "        # Ensure API keys are loaded from environment variables\n",
        "        # Assuming alpaca_api_key_id and alpaca_api_secret_key are already loaded\n",
        "        # in a previous step (e.g., from a .env file)\n",
        "\n",
        "        api_key_id = os.getenv('APCA_API_KEY_ID')\n",
        "        api_secret_key = os.getenv('APCA_API_SECRET_KEY')\n",
        "        base_url = os.getenv('APCA_API_BASE_URL', 'https://paper-api.alpaca.markets') # Default to paper trading URL\n",
        "\n",
        "        if not api_key_id or not api_secret_key:\n",
        "            logger.error(\"Alpaca API keys (APCA_API_KEY_ID and APCA_API_SECRET_KEY) not found in environment variables. Cannot initialize API.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"Attempting to initialize Alpaca API with base URL: {base_url}\")\n",
        "            api = tradeapi.REST(api_key_id, api_secret_key, base_url, api_version='v2')\n",
        "            logger.info(\"Alpaca API object initialized successfully.\")\n",
        "            return api\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error initializing Alpaca API: {e}\", exc_info=True)\n",
        "            return None\n",
        "\n",
        "    # Removed type hint api: tradeapi.REST\n",
        "    def check_alpaca_connection(api):\n",
        "        \"\"\"\n",
        "        Checks the status of the Alpaca API connection with logging and error handling.\n",
        "        \"\"\"\n",
        "        if api is None:\n",
        "            logger.warning(\"Alpaca API object is not initialized. Cannot check connection.\")\n",
        "            return False\n",
        "\n",
        "        try:\n",
        "            logger.info(\"Checking Alpaca API connection...\")\n",
        "            account = api.get_account()\n",
        "            logger.info(f\"Alpaca API connection successful. Account Status: {account.status}\")\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error checking Alpaca API connection: {e}\", exc_info=True)\n",
        "            return False\n",
        "\n",
        "    def place_order(api, symbol: str, qty: int, side: str, type: str, time_in_force: str, limit_price: float = None, stop_price: float = None):\n",
        "        \"\"\"\n",
        "        Places a trade order using the Alpaca API with logging and error handling.\n",
        "\n",
        "        Args:\n",
        "            api: An initialized Alpaca API REST object.\n",
        "            symbol: The stock symbol.\n",
        "            qty: The number of shares to trade.\n",
        "            side: The trade side ('buy' or 'sell').\n",
        "            type: The order type ('market', 'limit', 'stop', 'stop_limit', 'trailing_stop').\n",
        "            time_in_force: The time in force ('day', 'gtc', 'opg', 'cls', 'ioc', 'fotc').\n",
        "            limit_price: The limit price for limit orders.\n",
        "            stop_price: The stop price for stop orders.\n",
        "\n",
        "        Returns:\n",
        "            The placed order object or None if an error occurred.\n",
        "        \"\"\"\n",
        "        if api is None:\n",
        "            logger.warning(\"Alpaca API object is not initialized. Cannot place order.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"Attempting to place a {side} order for {qty} shares of {symbol} (Type: {type}, TIF: {time_in_force}).\")\n",
        "            order = api.submit_order(\n",
        "                symbol=symbol,\n",
        "                qty=qty,\n",
        "                side=side,\n",
        "                type=type,\n",
        "                time_in_force=time_in_force,\n",
        "                limit_price=limit_price,\n",
        "                stop_price=stop_price\n",
        "            )\n",
        "            logger.info(f\"Order placed successfully: {order.id}\")\n",
        "            return order\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error placing order for {symbol}: {e}\", exc_info=True)\n",
        "            return None\n",
        "\n",
        "    def get_order_status(api, order_id: str):\n",
        "        \"\"\"\n",
        "        Gets the status of a specific order using the Alpaca API with logging and error handling.\n",
        "\n",
        "        Args:\n",
        "            api: An initialized Alpaca API REST object.\n",
        "            order_id: The ID of the order to check.\n",
        "\n",
        "        Returns:\n",
        "            The order object or None if an error occurred or order not found.\n",
        "        \"\"\"\n",
        "        if api is None:\n",
        "            logger.warning(\"Alpaca API object is not initialized. Cannot get order status.\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            logger.info(f\"Attempting to get status for order ID: {order_id}\")\n",
        "            order = api.get_order(order_id)\n",
        "            logger.info(f\"Successfully retrieved status for order {order_id}: {order.status}\")\n",
        "            return order\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting status for order ID {order_id}: {e}\", exc_info=True)\n",
        "            return None\n",
        "\n",
        "    def get_open_positions(api):\n",
        "        \"\"\"\n",
        "        Gets all open positions using the Alpaca API with logging and error handling.\n",
        "\n",
        "        Args:\n",
        "            api: An initialized Alpaca API REST object.\n",
        "\n",
        "        Returns:\n",
        "            A list of position objects or an empty list if no open positions or an error occurred.\n",
        "        \"\"\"\n",
        "        if api is None:\n",
        "            logger.warning(\"Alpaca API object is not initialized. Cannot get open positions.\")\n",
        "            return []\n",
        "\n",
        "        try:\n",
        "            logger.info(\"Attempting to get open positions.\")\n",
        "            positions = api.list_positions()\n",
        "            logger.info(f\"Successfully retrieved {len(positions)} open positions.\")\n",
        "            return positions\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error getting open positions: {e}\", exc_info=True)\n",
        "            return []\n",
        "\n",
        "except ImportError as e:\n",
        "    print(f\"ImportError: {e}\")\n",
        "    print(\"Alpaca API functionality is unavailable due to import issues.\")\n",
        "    tradeapi = None # Set tradeapi to None if import fails\n",
        "    # Define dummy functions if import fails to prevent NameError later\n",
        "    def initialize_alpaca_api(): return None\n",
        "    def check_alpaca_connection(api): return False\n",
        "    def place_order(api, symbol, qty, side, type, time_in_force, limit_price = None, stop_price = None): return None\n",
        "    def get_order_status(api, order_id): return None\n",
        "    def get_open_positions(api): return []\n",
        "\n",
        "print(\"Alpaca trading functions defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e2b9b26"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempts to install numpy, scipy, and scikit-learn to resolve the `ImportError` have failed due to persistent dependency conflicts with pre-installed Colab packages. I will try reinstalling a specific set of versions that were partially successful in previous attempts, hoping this combination resolves the import issues and allows the machine learning modules to be imported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "599d4449",
        "outputId": "6284eb4f-6919-469c-8cf8-0f0532cddd04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy==1.12.0\n",
            "  Using cached scipy-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "Collecting scikit-learn==1.4.2\n",
            "  Using cached scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn==1.4.2)\n",
            "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn==1.4.2)\n",
            "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Using cached scipy-1.12.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.8 MB)\n",
            "Using cached scikit_learn-1.4.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n",
            "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
            "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.6.0\n",
            "    Uninstalling threadpoolctl-3.6.0:\n",
            "      Successfully uninstalled threadpoolctl-3.6.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.4\n",
            "    Uninstalling numpy-2.3.4:\n",
            "      Successfully uninstalled numpy-2.3.4\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.5.2\n",
            "    Uninstalling joblib-1.5.2:\n",
            "      Successfully uninstalled joblib-1.5.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.12.0\n",
            "    Uninstalling scipy-1.12.0:\n",
            "      Successfully uninstalled scipy-1.12.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.4.2\n",
            "    Uninstalling scikit-learn-1.4.2:\n",
            "      Successfully uninstalled scikit-learn-1.4.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-ta 0.4.71b0 requires numpy>=2.2.6, but you have numpy 1.26.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "yfinance 0.2.66 requires websockets>=13.0, but you have websockets 10.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "dask-cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.3 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.12.0 which is incompatible.\n",
            "cuml-cu12 25.6.0 requires scikit-learn>=1.5, but you have scikit-learn 1.4.2 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.4.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed joblib-1.5.2 numpy-1.26.4 scikit-learn-1.4.2 scipy-1.12.0 threadpoolctl-3.6.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "af7d942f2af94b0d88c76c0eda0ab8bb",
              "pip_warning": {
                "packages": [
                  "joblib",
                  "numpy",
                  "scipy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy.char'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1291484689.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Import necessary machine learning modules from sklearn and others\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0m_distributor_init\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     )\n\u001b[0;32m---> 87\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInconsistentVersionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_estimator_html_repr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HTMLDocumentationLinkMixin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_html_repr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata_requests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_MetadataRequester\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/sparse/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csr\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_csc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/sparse/_base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisibleDeprecationWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m from ._sputils import (asmatrix, check_reshape_kwargs, check_shape,\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_array_api\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0marray_namespace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/_array_api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_api_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_api_compat\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marray_api_compat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_api_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_api_compat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_api_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_api_compat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0marray_api_compat_numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'array_namespace'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'as_xparray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/scipy/_lib/array_api_compat/array_api_compat/numpy/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# from numpy import * doesn't overwrite these builtin names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m             msg = (\"The current Numpy installation ({!r}) fails to \"\n\u001b[0m\u001b[1;32m    368\u001b[0m                    \u001b[0;34m\"pass simple sanity checks. This can be caused for example \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m                    \u001b[0;34m\"by incorrect BLAS library being linked in, or by mixing \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.char'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Attempt to install a potentially compatible set of versions again\n",
        "# based on previous output suggesting scikit-learn 1.4.2, scipy 1.12.0, and numpy 1.26.4\n",
        "%pip install --upgrade --force-reinstall numpy==1.26.4 scipy==1.12.0 scikit-learn==1.4.2\n",
        "\n",
        "# Import necessary machine learning modules from sklearn and others\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger('ApexAMMO')\n",
        "\n",
        "# Assume 'historical_data' DataFrame is available from the data acquisition step\n",
        "# and 'df_with_indicators' from the stock analysis step.\n",
        "# If not available, create a dummy DataFrame for demonstration.\n",
        "# This block is copied from the previous attempt but will now run after the\n",
        "# potentially successful installation.\n",
        "if 'df_with_indicators' not in locals() or df_with_indicators.empty:\n",
        "    logger.warning(\"Using dummy data as 'df_with_indicators' was not found or is empty.\")\n",
        "    # Create a dummy technical_data DataFrame\n",
        "    data = {\n",
        "        'Open': np.random.rand(100) * 100 + 50,\n",
        "        'High': np.random.rand(100) * 100 + 55,\n",
        "        'Low': np.random.rand(100) * 100 + 45,\n",
        "        'Close': np.random.rand(100) * 100 + 50,\n",
        "        'Volume': np.random.rand(100) * 1000000,\n",
        "        'RSI_14': np.random.rand(100) * 50 + 25,\n",
        "        'MACD_12_26_9': np.random.rand(100) * 5 - 2.5,\n",
        "        'MACDH_12_26_9': np.random.rand(100) * 2 - 1,\n",
        "        'MACDS_12_26_9': np.random.rand(100) * 4 - 2,\n",
        "    }\n",
        "    index = pd.date_range(start='2023-01-01', periods=100, freq='D')\n",
        "    df_with_indicators = pd.DataFrame(data, index=index)\n",
        "    # Ensure SMA columns are present, even if dummy\n",
        "    df_with_indicators['SMA_20'] = df_with_indicators['Close'].rolling(window=20).mean().fillna(0)\n",
        "    df_with_indicators['SMA_50'] = df_with_indicators['Close'].rolling(window=50).mean().fillna(0)\n",
        "\n",
        "\n",
        "# Prepare the target variable: 1 if next day's close is higher, 0 otherwise\n",
        "df_with_indicators['Target'] = (df_with_indicators['Close'].shift(-1) > df_with_indicators['Close']).astype(int)\n",
        "\n",
        "# Drop the last row as it will have NaN for the Target\n",
        "df_with_indicators.dropna(subset=['Target'], inplace=True)\n",
        "\n",
        "logger.info(\"Data prepared for ML training.\")\n",
        "display(df_with_indicators.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97d31a74"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to install specific versions of numpy, scipy, and scikit-learn did not resolve the import error. The traceback indicates a conflict with the installed numpy version. I will try reinstalling these libraries again without specifying versions to see if pip can find a compatible set that resolves the `ImportError`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ef53f4f2"
      },
      "outputs": [],
      "source": [
        "# Attempt to install compatible versions of numpy, scipy, and scikit-learn\n",
        "%pip install --upgrade --force-reinstall numpy scipy scikit-learn\n",
        "\n",
        "# Import necessary machine learning modules from sklearn and others\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger('ApexAMMO')\n",
        "\n",
        "# Assume 'historical_data' DataFrame is available from the data acquisition step\n",
        "# and 'df_with_indicators' from the stock analysis step.\n",
        "# If not available, create a dummy DataFrame for demonstration.\n",
        "# This block is copied from the previous attempt but will now run after the\n",
        "# potentially successful installation.\n",
        "if 'df_with_indicators' not in locals() or df_with_indicators.empty:\n",
        "    logger.warning(\"Using dummy data as 'df_with_indicators' was not found or is empty.\")\n",
        "    # Create a dummy technical_data DataFrame\n",
        "    data = {\n",
        "        'Open': np.random.rand(100) * 100 + 50,\n",
        "        'High': np.random.rand(100) * 100 + 55,\n",
        "        'Low': np.random.rand(100) * 100 + 45,\n",
        "        'Close': np.random.rand(100) * 100 + 50,\n",
        "        'Volume': np.random.rand(100) * 1000000,\n",
        "        'RSI_14': np.random.rand(100) * 50 + 25,\n",
        "        'MACD_12_26_9': np.random.rand(100) * 5 - 2.5,\n",
        "        'MACDH_12_26_9': np.random.rand(100) * 2 - 1,\n",
        "        'MACDS_12_26_9': np.random.rand(100) * 4 - 2,\n",
        "    }\n",
        "    index = pd.date_range(start='2023-01-01', periods=100, freq='D')\n",
        "    df_with_indicators = pd.DataFrame(data, index=index)\n",
        "    # Ensure SMA columns are present, even if dummy\n",
        "    df_with_indicators['SMA_20'] = df_with_indicators['Close'].rolling(window=20).mean().fillna(0)\n",
        "    df_with_indicators['SMA_50'] = df_with_indicators['Close'].rolling(window=50).mean().fillna(0)\n",
        "\n",
        "\n",
        "# Prepare the target variable: 1 if next day's close is higher, 0 otherwise\n",
        "df_with_indicators['Target'] = (df_with_indicators['Close'].shift(-1) > df_with_indicators['Close']).astype(int)\n",
        "\n",
        "# Drop the last row as it will have NaN for the Target\n",
        "df_with_indicators.dropna(subset=['Target'], inplace=True)\n",
        "\n",
        "logger.info(\"Data prepared for ML training.\")\n",
        "display(df_with_indicators.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8e5afc0"
      },
      "source": [
        "## Machine learning integration (Continued)\n",
        "\n",
        "### Subtask:\n",
        "Resolve library import issues and implement machine learning models for predictive modeling and pattern recognition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9068ec2c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempts to import machine learning libraries failed due to version conflicts between numpy, scipy, and scikit-learn. I will attempt to install specific versions of these libraries that are known to be compatible. After successful installation and import, I will proceed with preparing the data, training a simple model (e.g., RandomForestClassifier), and implementing a prediction function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "086fb553"
      },
      "outputs": [],
      "source": [
        "# Attempt to install compatible versions of numpy, scipy, and scikit-learn\n",
        "%pip install --upgrade --force-reinstall numpy==1.26.4 scipy==1.12.0 scikit-learn==1.4.2\n",
        "\n",
        "# Import necessary machine learning modules from sklearn and others\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger('ApexAMMO')\n",
        "\n",
        "# Assume 'historical_data' DataFrame is available from the data acquisition step\n",
        "# and 'df_with_indicators' from the stock analysis step.\n",
        "# If not available, create a dummy DataFrame for demonstration.\n",
        "# This block is copied from the previous attempt but will now run after the\n",
        "# potentially successful installation.\n",
        "if 'df_with_indicators' not in locals() or df_with_indicators.empty:\n",
        "    logger.warning(\"Using dummy data as 'df_with_indicators' was not found or is empty.\")\n",
        "    # Create a dummy technical_data DataFrame\n",
        "    data = {\n",
        "        'Open': np.random.rand(100) * 100 + 50,\n",
        "        'High': np.random.rand(100) * 100 + 55,\n",
        "        'Low': np.random.rand(100) * 100 + 45,\n",
        "        'Close': np.random.rand(100) * 100 + 50,\n",
        "        'Volume': np.random.rand(100) * 1000000,\n",
        "        'RSI_14': np.random.rand(100) * 50 + 25,\n",
        "        'MACD_12_26_9': np.random.rand(100) * 5 - 2.5,\n",
        "        'MACDH_12_26_9': np.random.rand(100) * 2 - 1,\n",
        "        'MACDS_12_26_9': np.random.rand(100) * 4 - 2,\n",
        "    }\n",
        "    index = pd.date_range(start='2023-01-01', periods=100, freq='D')\n",
        "    df_with_indicators = pd.DataFrame(data, index=index)\n",
        "    # Ensure SMA columns are present, even if dummy\n",
        "    df_with_indicators['SMA_20'] = df_with_indicators['Close'].rolling(window=20).mean().fillna(0)\n",
        "    df_with_indicators['SMA_50'] = df_with_indicators['Close'].rolling(window=50).mean().fillna(0)\n",
        "\n",
        "\n",
        "# Prepare the target variable: 1 if next day's close is higher, 0 otherwise\n",
        "df_with_indicators['Target'] = (df_with_indicators['Close'].shift(-1) > df_with_indicators['Close']).astype(int)\n",
        "\n",
        "# Drop the last row as it will have NaN for the Target\n",
        "df_with_indicators.dropna(subset=['Target'], inplace=True)\n",
        "\n",
        "logger.info(\"Data prepared for ML training.\")\n",
        "display(df_with_indicators.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f9b282b"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the required Python libraries for data manipulation, financial data fetching, technical analysis, machine learning, and broker API interaction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "353899b8"
      },
      "outputs": [],
      "source": [
        "%pip install pandas yfinance finnhub-python pandas_ta scikit-learn alpaca-trade-api python-dotenv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebbc708d"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a `.env` file to securely store the API keys and then load these environment variables. This follows the best practice for handling sensitive information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c7c89517"
      },
      "outputs": [],
      "source": [
        "%%writefile .env\n",
        "FINNHUB_API_KEY=YOUR_FINNHUB_API_KEY\n",
        "APCA_API_KEY_ID=YOUR_ALPACA_API_KEY_ID\n",
        "APCA_API_SECRET_KEY=YOUR_ALPACA_API_SECRET_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d27b24ad"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the environment variables from the `.env` file into the current environment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7fd22b1a"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "finnhub_api_key = os.getenv('FINNHUB_API_KEY')\n",
        "alpaca_api_key_id = os.getenv('APCA_API_KEY_ID')\n",
        "alpaca_api_secret_key = os.getenv('APCA_API_SECRET_KEY')\n",
        "\n",
        "print(\"Environment variables loaded.\")\n",
        "# You can verify by printing a part of the keys (be cautious not to print the full key)\n",
        "# print(f\"Finnhub Key (first 5 chars): {finnhub_api_key[:5] if finnhub_api_key else None}\")\n",
        "# print(f\"Alpaca Key ID (first 5 chars): {alpaca_api_key_id[:5] if alpaca_api_key_id else None}\")\n",
        "# print(f\"Alpaca Secret Key (first 5 chars): {alpaca_api_secret_key[:5] if alpaca_api_secret_key else None}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26609f9f"
      },
      "source": [
        "## Data acquisition\n",
        "\n",
        "### Subtask:\n",
        "Write code to fetch historical stock data, real-time data, and news headlines from sources like Yahoo Finance and Finnhub.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad4ae16a"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary libraries and define functions to fetch historical data, real-time data, and news headlines using yfinance and Finnhub with basic error handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6d36bd68"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import finnhub\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Finnhub client\n",
        "# Ensure finnhub_api_key is loaded from environment variables as done in the previous step\n",
        "if 'finnhub_api_key' not in locals() or finnhub_api_key is None:\n",
        "    print(\"Finnhub API key not found. Please ensure it is loaded from the environment.\")\n",
        "    finnhub_client = None\n",
        "else:\n",
        "    finnhub_client = finnhub.Client(api_key=finnhub_api_key)\n",
        "\n",
        "\n",
        "def fetch_historical_data(ticker, start_date, end_date):\n",
        "    \"\"\"Fetches historical stock data using yfinance.\"\"\"\n",
        "    try:\n",
        "        data = yf.download(ticker, start=start_date, end=end_date)\n",
        "        if data.empty:\n",
        "            print(f\"No historical data found for ticker: {ticker}\")\n",
        "            return None\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching historical data for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_realtime_data(ticker):\n",
        "    \"\"\"Fetches real-time stock data using Finnhub.\"\"\"\n",
        "    if finnhub_client is None:\n",
        "        return None\n",
        "    try:\n",
        "        quote = finnhub_client.quote(ticker)\n",
        "        if quote and 'c' in quote:\n",
        "            return quote\n",
        "        else:\n",
        "            print(f\"Could not retrieve real-time data for ticker: {ticker}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching real-time data for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_news_headlines(ticker=None, category=None):\n",
        "    \"\"\"Fetches news headlines using Finnhub.\"\"\"\n",
        "    if finnhub_client is None:\n",
        "        return None\n",
        "    try:\n",
        "        if ticker:\n",
        "            news = finnhub_client.company_news(ticker, _from=\"2023-01-01\", to=\"2023-12-31\") # Using a fixed date range for company news\n",
        "        elif category:\n",
        "             news = finnhub_client.general_news(category=category, min_id=0) # Using min_id for general news\n",
        "        else:\n",
        "            print(\"Please provide either a ticker or a category for news.\")\n",
        "            return None\n",
        "\n",
        "        if news:\n",
        "            return news\n",
        "        else:\n",
        "            print(f\"No news found for ticker: {ticker} or category: {category}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching news: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage (optional, for testing the functions)\n",
        "# historical_data = fetch_historical_data(\"AAPL\", \"2022-01-01\", \"2022-12-31\")\n",
        "# if historical_data is not None:\n",
        "#     print(\"\\nHistorical Data (first 5 rows):\")\n",
        "#     display(historical_data.head())\n",
        "\n",
        "# realtime_data = fetch_realtime_data(\"AAPL\")\n",
        "# if realtime_data is not None:\n",
        "#      print(f\"\\nReal-time Data for AAPL: {realtime_data}\")\n",
        "\n",
        "# company_news = fetch_news_headlines(ticker=\"AAPL\")\n",
        "# if company_news is not None:\n",
        "#     print(f\"\\nLatest News for AAPL ({len(company_news)} articles):\")\n",
        "#     # Print titles of a few articles\n",
        "#     for article in company_news[:5]:\n",
        "#         print(f\"- {article.get('headline')}\")\n",
        "\n",
        "# general_news = fetch_news_headlines(category=\"general\")\n",
        "# if general_news is not None:\n",
        "#     print(f\"\\nLatest General News ({len(general_news)} articles):\")\n",
        "#     # Print titles of a few articles\n",
        "#     for article in general_news[:5]:\n",
        "#          print(f\"- {article.get('headline')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae547855"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt failed due to a ModuleNotFoundError related to urllib3 and six. This often indicates a conflict or issue with the installed versions of these libraries or their dependencies. Reinstalling the relevant packages might resolve this. Since the error originates from importing `finnhub` which depends on `requests` and `urllib3`, reinstalling `finnhub-python` and potentially `requests` and `urllib3` could fix the issue.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2MeA-uJBMvLT"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --force-reinstall finnhub-python requests urllib3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5147925"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous installation attempt completed. Now, try running the code to import the libraries and define the data fetching functions again to see if the reinstall fixed the ModuleNotFoundError.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6c20a354"
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import finnhub\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Finnhub client\n",
        "# Ensure finnhub_api_key is loaded from environment variables as done in the previous step\n",
        "if 'finnhub_api_key' not in locals() or finnhub_api_key is None:\n",
        "    print(\"Finnhub API key not found. Please ensure it is loaded from the environment.\")\n",
        "    finnhub_client = None\n",
        "else:\n",
        "    finnhub_client = finnhub.Client(api_key=finnhub_api_key)\n",
        "\n",
        "\n",
        "def fetch_historical_data(ticker, start_date, end_date):\n",
        "    \"\"\"Fetches historical stock data using yfinance.\"\"\"\n",
        "    try:\n",
        "        data = yf.download(ticker, start=start_date, end=end_date)\n",
        "        if data.empty:\n",
        "            print(f\"No historical data found for ticker: {ticker}\")\n",
        "            return None\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching historical data for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_realtime_data(ticker):\n",
        "    \"\"\"Fetches real-time stock data using Finnhub.\"\"\"\n",
        "    if finnhub_client is None:\n",
        "        return None\n",
        "    try:\n",
        "        quote = finnhub_client.quote(ticker)\n",
        "        if quote and 'c' in quote:\n",
        "            return quote\n",
        "        else:\n",
        "            print(f\"Could not retrieve real-time data for ticker: {ticker}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching real-time data for {ticker}: {e}\")\n",
        "        return None\n",
        "\n",
        "def fetch_news_headlines(ticker=None, category=None):\n",
        "    \"\"\"Fetches news headlines using Finnhub.\"\"\"\n",
        "    if finnhub_client is None:\n",
        "        return None\n",
        "    try:\n",
        "        if ticker:\n",
        "            news = finnhub_client.company_news(ticker, _from=\"2023-01-01\", to=\"2023-12-31\") # Using a fixed date range for company news\n",
        "        elif category:\n",
        "             news = finnhub_client.general_news(category=category, min_id=0) # Using min_id for general news\n",
        "        else:\n",
        "            print(\"Please provide either a ticker or a category for news.\")\n",
        "            return None\n",
        "\n",
        "        if news:\n",
        "            return news\n",
        "        else:\n",
        "            print(f\"No news found for ticker: {ticker} or category: {category}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching news: {e}\")\n",
        "        return None\n",
        "\n",
        "# Example usage (optional, for testing the functions)\n",
        "# historical_data = fetch_historical_data(\"AAPL\", \"2022-01-01\", \"2022-12-31\")\n",
        "# if historical_data is not None:\n",
        "#     print(\"\\nHistorical Data (first 5 rows):\")\n",
        "#     display(historical_data.head())\n",
        "\n",
        "# realtime_data = fetch_realtime_data(\"AAPL\")\n",
        "# if realtime_data is not None:\n",
        "#      print(f\"\\nReal-time Data for AAPL: {realtime_data}\")\n",
        "\n",
        "# company_news = fetch_news_headlines(ticker=\"AAPL\")\n",
        "# if company_news is not None:\n",
        "#     print(f\"\\nLatest News for AAPL ({len(company_news)} articles):\")\n",
        "#     # Print titles of a few articles\n",
        "#     for article in company_news[:5]:\n",
        "#         print(f\"- {article.get('headline')}\")\n",
        "\n",
        "# general_news = fetch_news_headlines(category=\"general\")\n",
        "# if general_news is not None:\n",
        "#     print(f\"\\nLatest General News ({len(general_news)} articles):\")\n",
        "#     # Print titles of a few articles\n",
        "#     for article in general_news[:5]:\n",
        "#          print(f\"- {article.get('headline')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5757ec60"
      },
      "source": [
        "## Stock analysis\n",
        "\n",
        "### Subtask:\n",
        "Develop modules for technical analysis (using indicators like RSI, MACD, moving averages) and implement the logic to determine market personality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "741f210a"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the functions for calculating technical indicators and determining market personality as described in the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "92e46c49"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import numpy as np\n",
        "\n",
        "def calculate_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates technical indicators and adds them as new columns to the DataFrame.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame containing historical stock data with columns ['Open', 'High', 'Low', 'Close', 'Volume'].\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with added technical indicator columns.\n",
        "    \"\"\"\n",
        "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
        "        print(\"Input is not a valid pandas DataFrame or is empty.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    # Flatten MultiIndex columns if they exist\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "        # Assuming the relevant data is in the second level of the MultiIndex\n",
        "        df.columns = df.columns.get_level_values(1)\n",
        "        # Rename columns to standard names if necessary (e.g., 'Close' instead of 'AAPL')\n",
        "        # This might require inspecting the actual column names after flattening\n",
        "        # For now, assuming the second level contains standard names like 'Close', 'Volume', etc.\n",
        "        # If not, additional renaming logic is needed here.\n",
        "\n",
        "\n",
        "    # Ensure required columns exist\n",
        "    required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        print(f\"DataFrame must contain the following columns: {required_cols}\")\n",
        "        return df\n",
        "\n",
        "    try:\n",
        "        # Calculate RSI\n",
        "        df.ta.rsi(append=True)\n",
        "\n",
        "        # Calculate MACD\n",
        "        df.ta.macd(append=True)\n",
        "\n",
        "        # Calculate Moving Averages (e.g., SMA 20 and SMA 50)\n",
        "        df.ta.sma(length=20, append=True)\n",
        "        df.ta.sma(length=50, append=True)\n",
        "\n",
        "        # Add other indicators as needed\n",
        "        # df.ta.bbands(append=True)\n",
        "        # df.ta.atr(append=True)\n",
        "\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating technical indicators: {e}\")\n",
        "        return df\n",
        "\n",
        "def determine_market_personality(df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Determines the market personality based on technical indicators.\n",
        "\n",
        "    Args:\n",
        "        df: DataFrame with calculated technical indicators.\n",
        "\n",
        "    Returns:\n",
        "        A string indicating the market personality (e.g., 'Trending Up', 'Trending Down', 'Range-Bound', 'Undetermined').\n",
        "    \"\"\"\n",
        "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
        "        print(\"Input is not a valid pandas DataFrame or is empty.\")\n",
        "        return 'Undetermined'\n",
        "\n",
        "    # Ensure columns are flattened before proceeding\n",
        "    if isinstance(df.columns, pd.MultiIndex):\n",
        "         df.columns = df.columns.get_level_values(1)\n",
        "         # Add renaming logic if needed\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Example rules for determining market personality\n",
        "        # These rules are simplified and can be expanded/refined\n",
        "\n",
        "        # Check for trending market based on moving averages\n",
        "        df['SMA_20'] = df['SMA_20'].fillna(0)\n",
        "        df['SMA_50'] = df['SMA_50'].fillna(0)\n",
        "\n",
        "        if df['SMA_20'].iloc[-1] > df['SMA_50'].iloc[-1] and df['Close'].iloc[-1] > df['SMA_20'].iloc[-1]:\n",
        "            # Check for recent upward momentum (e.g., positive MACD histogram)\n",
        "            if 'MACDH_12_26_9' in df.columns and df['MACDH_12_26_9'].iloc[-1] > 0:\n",
        "                 return 'Trending Up'\n",
        "            elif 'MACDH_12_26_9' not in df.columns:\n",
        "                # Fallback if MACD not calculated\n",
        "                 return 'Trending Up'\n",
        "\n",
        "\n",
        "        elif df['SMA_20'].iloc[-1] < df['SMA_50'].iloc[-1] and df['Close'].iloc[-1] < df['SMA_20'].iloc[-1]:\n",
        "            # Check for recent downward momentum (e.g., negative MACD histogram)\n",
        "            if 'MACDH_12_26_9' in df.columns and df['MACDH_12_26_9'].iloc[-1] < 0:\n",
        "                return 'Trending Down'\n",
        "            elif 'MACDH_12_26_9' not in df.columns:\n",
        "                 # Fallback if MACD not calculated\n",
        "                 return 'Trending Down'\n",
        "\n",
        "        # Check for range-bound market (e.g., RSI around 50, moving averages close)\n",
        "        if 'RSI_14' in df.columns and 40 < df['RSI_14'].iloc[-1] < 60:\n",
        "             # Check if SMAs are close (within a certain percentage)\n",
        "             if abs(df['SMA_20'].iloc[-1] - df['SMA_50'].iloc[-1]) / df['SMA_50'].iloc[-1] < 0.02: # Example: within 2%\n",
        "                 return 'Range-Bound'\n",
        "\n",
        "        return 'Undetermined'\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error determining market personality: {e}\")\n",
        "        return 'Undetermined'\n",
        "\n",
        "# Example usage (requires a sample DataFrame 'historical_data' from the previous step)\n",
        "# Assuming 'historical_data' DataFrame is available from the data acquisition step\n",
        "# if 'historical_data' in locals() and historical_data is not None and not historical_data.empty:\n",
        "#     df_with_indicators = calculate_technical_indicators(historical_data.copy())\n",
        "#     if not df_with_indicators.empty:\n",
        "#         print(\"\\nDataFrame with Technical Indicators (last 5 rows):\")\n",
        "#         display(df_with_indicators.tail())\n",
        "#         market_personality = determine_market_personality(df_with_indicators.copy())\n",
        "#         print(f\"\\nMarket Personality: {market_personality}\")\n",
        "# else:\n",
        "#     print(\"\\n'historical_data' DataFrame not found or is empty. Cannot run example usage for technical analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdaa461d"
      },
      "source": [
        "## Sentiment analysis\n",
        "\n",
        "### Subtask:\n",
        "Implement a sentiment analysis model to process news headlines and gauge market sentiment.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbbeafec"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the sentiment analysis model by importing necessary libraries, downloading resources, and defining a function to analyze news headlines.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fb72d263"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download VADER lexicon for sentiment analysis\n",
        "try:\n",
        "    nltk.data.find('sentiment/vader_lexicon.zip')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('vader_lexicon')\n",
        "except LookupError:\n",
        "     nltk.download('vader_lexicon')\n",
        "\n",
        "\n",
        "def analyze_sentiment(headline: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyzes the sentiment of a news headline using NLTK's VADER.\n",
        "\n",
        "    Args:\n",
        "        headline: The news headline string.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing sentiment scores (neg, neu, pos, compound)\n",
        "        or an error indicator if analysis fails.\n",
        "    \"\"\"\n",
        "    if not isinstance(headline, str) or not headline:\n",
        "        print(\"Input is not a valid string or is empty.\")\n",
        "        return {\"error\": \"Invalid input headline\"}\n",
        "\n",
        "    try:\n",
        "        analyzer = SentimentIntensityAnalyzer()\n",
        "        sentiment_scores = analyzer.polarity_scores(headline)\n",
        "        return sentiment_scores\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing sentiment for headline '{headline}': {e}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Example usage:\n",
        "# headline1 = \"Apple stock soars after strong earnings report.\"\n",
        "# sentiment1 = analyze_sentiment(headline1)\n",
        "# print(f\"Headline: '{headline1}'\\nSentiment: {sentiment1}\")\n",
        "\n",
        "# headline2 = \"Market experiences a slight downturn today.\"\n",
        "# sentiment2 = analyze_sentiment(headline2)\n",
        "# print(f\"Headline: '{headline2}'\\nSentiment: {sentiment2}\")\n",
        "\n",
        "# headline3 = \"Company announces new product launch.\"\n",
        "# sentiment3 = analyze_sentiment(headline3)\n",
        "# print(f\"Headline: '{headline3}'\\nSentiment: {sentiment3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "609413b7"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to download the NLTK data failed due to an AttributeError in the exception handling. A simpler approach is to directly attempt the download and catch the general Exception or LookupError if the resource is not found. Also, the `nltk.data.find` is not needed before downloading.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zs1onPkHNIJs"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download VADER lexicon for sentiment analysis\n",
        "try:\n",
        "    nltk.download('vader_lexicon')\n",
        "except Exception as e:\n",
        "    print(f\"Error downloading vader_lexicon: {e}\")\n",
        "\n",
        "\n",
        "def analyze_sentiment(headline: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyzes the sentiment of a news headline using NLTK's VADER.\n",
        "\n",
        "    Args:\n",
        "        headline: The news headline string.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing sentiment scores (neg, neu, pos, compound)\n",
        "        or an error indicator if analysis fails.\n",
        "    \"\"\"\n",
        "    if not isinstance(headline, str) or not headline:\n",
        "        print(\"Input is not a valid string or is empty.\")\n",
        "        return {\"error\": \"Invalid input headline\"}\n",
        "\n",
        "    try:\n",
        "        # Initialize the analyzer inside the function to ensure it's ready\n",
        "        # after potential download\n",
        "        analyzer = SentimentIntensityAnalyzer()\n",
        "        sentiment_scores = analyzer.polarity_scores(headline)\n",
        "        return sentiment_scores\n",
        "    except Exception as e:\n",
        "        print(f\"Error analyzing sentiment for headline '{headline}': {e}\")\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Example usage:\n",
        "# headline1 = \"Apple stock soars after strong earnings report.\"\n",
        "# sentiment1 = analyze_sentiment(headline1)\n",
        "# print(f\"Headline: '{headline1}'\\nSentiment: {sentiment1}\")\n",
        "\n",
        "# headline2 = \"Market experiences a slight downturn today.\"\n",
        "# sentiment2 = analyze_sentiment(headline2)\n",
        "# print(f\"Headline: '{headline2}'\\nSentiment: {sentiment2}\")\n",
        "\n",
        "# headline3 = \"Company announces new product launch.\"\n",
        "# sentiment3 = analyze_sentiment(headline3)\n",
        "# print(f\"Headline: '{headline3}'\\nSentiment: {sentiment3}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87e4bfec"
      },
      "source": [
        "## Trading signal generation\n",
        "\n",
        "### Subtask:\n",
        "Combine technical and sentiment analysis results to generate BUY, SELL, or HOLD signals based on the defined rules.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "598016ac"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the `generate_trading_signal` function, implement the trading signal logic based on technical and sentiment analysis, define signal types, and include basic error handling as per the instructions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "139741da"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def generate_trading_signal(technical_data: pd.DataFrame, sentiment_scores: dict) -> str:\n",
        "    \"\"\"\n",
        "    Generates a trading signal (BUY, SELL, HOLD) based on technical indicators\n",
        "    and sentiment analysis results.\n",
        "\n",
        "    Args:\n",
        "        technical_data: DataFrame containing historical stock data with calculated\n",
        "                        technical indicators (e.g., RSI, MACD, SMA).\n",
        "        sentiment_scores: A dictionary containing sentiment scores, likely\n",
        "                          including a 'compound' score.\n",
        "\n",
        "    Returns:\n",
        "        A string representing the trading signal ('BUY', 'SELL', 'HOLD', 'UNDETERMINED').\n",
        "    \"\"\"\n",
        "    if not isinstance(technical_data, pd.DataFrame) or technical_data.empty:\n",
        "        print(\"Technical data input is not a valid pandas DataFrame or is empty.\")\n",
        "        return 'UNDETERMINED'\n",
        "    if not isinstance(sentiment_scores, dict) or 'compound' not in sentiment_scores:\n",
        "        print(\"Sentiment scores input is not a valid dictionary or is missing 'compound' score.\")\n",
        "        return 'UNDETERMINED'\n",
        "\n",
        "    # Ensure required technical indicator columns exist and handle potential NaNs\n",
        "    required_tech_cols = ['RSI_14', 'MACD_12_26_9', 'MACDH_12_26_9', 'MACDS_12_26_9', 'SMA_20', 'SMA_50', 'Close']\n",
        "    if not all(col in technical_data.columns for col in required_tech_cols):\n",
        "        print(f\"Technical data DataFrame must contain the following columns: {required_tech_cols}\")\n",
        "        return 'UNDETERMINED'\n",
        "\n",
        "    # Use the latest available data for technical analysis\n",
        "    latest_data = technical_data.iloc[-1]\n",
        "\n",
        "    # Technical Analysis Rules (Example Rules - can be refined)\n",
        "    tech_buy_signal = False\n",
        "    tech_sell_signal = False\n",
        "\n",
        "    # Rule 1: Golden Cross (SMA_20 crosses above SMA_50) and SMA_20 is above SMA_50\n",
        "    # Need at least two data points to check for a crossover\n",
        "    if technical_data.shape[0] >= 2:\n",
        "        if technical_data['SMA_20'].iloc[-2] <= technical_data['SMA_50'].iloc[-2] and latest_data['SMA_20'] > latest_data['SMA_50']:\n",
        "            tech_buy_signal = True\n",
        "\n",
        "    # Rule 2: RSI indicates oversold condition and is turning up (simplified)\n",
        "    if latest_data['RSI_14'] < 30: # Example oversold threshold\n",
        "         # Check if RSI is increasing (requires looking at previous data points)\n",
        "         if technical_data.shape[0] >= 2 and technical_data['RSI_14'].iloc[-2] <= latest_data['RSI_14']:\n",
        "             tech_buy_signal = True\n",
        "\n",
        "\n",
        "    # Rule 3: MACD Crossover (MACD crosses above Signal Line)\n",
        "    # Need at least two data points to check for a crossover\n",
        "    if technical_data.shape[0] >= 2:\n",
        "         if technical_data['MACD_12_26_9'].iloc[-2] <= technical_data['MACDS_12_26_9'].iloc[-2] and latest_data['MACD_12_26_9'] > latest_data['MACDS_12_26_9']:\n",
        "             tech_buy_signal = True\n",
        "\n",
        "\n",
        "    # Rule 4: Death Cross (SMA_20 crosses below SMA_50) and SMA_20 is below SMA_50\n",
        "    # Need at least two data points to check for a crossover\n",
        "    if technical_data.shape[0] >= 2:\n",
        "        if technical_data['SMA_20'].iloc[-2] >= technical_data['SMA_50'].iloc[-2] and latest_data['SMA_20'] < latest_data['SMA_50']:\n",
        "            tech_sell_signal = True\n",
        "\n",
        "    # Rule 5: RSI indicates overbought condition and is turning down (simplified)\n",
        "    if latest_data['RSI_14'] > 70: # Example overbought threshold\n",
        "         # Check if RSI is decreasing (requires looking at previous data points)\n",
        "         if technical_data.shape[0] >= 2 and technical_data['RSI_14'].iloc[-2] >= latest_data['RSI_14']:\n",
        "             tech_sell_signal = True\n",
        "\n",
        "\n",
        "    # Rule 6: MACD Crossover (MACD crosses below Signal Line)\n",
        "    # Need at least two data points to check for a crossover\n",
        "    if technical_data.shape[0] >= 2:\n",
        "         if technical_data['MACD_12_26_9'].iloc[-2] >= technical_data['MACDS_12_26_9'].iloc[-2] and latest_data['MACD_12_26_9'] < latest_data['MACDS_12_26_9']:\n",
        "             tech_sell_signal = True\n",
        "\n",
        "\n",
        "    # Sentiment Analysis Rule (Example Rule - can be refined)\n",
        "    sentiment_compound_score = sentiment_scores.get('compound', 0)\n",
        "    sentiment_positive = sentiment_compound_score > 0.1 # Example positive threshold\n",
        "    sentiment_negative = sentiment_compound_score < -0.1 # Example negative threshold\n",
        "\n",
        "    # Combine Technical and Sentiment Analysis for Final Signal\n",
        "    if tech_buy_signal and sentiment_positive:\n",
        "        return 'BUY'\n",
        "    elif tech_sell_signal and sentiment_negative:\n",
        "        return 'SELL'\n",
        "    elif tech_buy_signal and not sentiment_negative: # Allow buy if technical is positive and sentiment is not explicitly negative\n",
        "        return 'BUY'\n",
        "    elif tech_sell_signal and not sentiment_positive: # Allow sell if technical is negative and sentiment is not explicitly positive\n",
        "         return 'SELL'\n",
        "    else:\n",
        "        return 'HOLD'\n",
        "\n",
        "# Example Usage (Requires sample data for technical_data and sentiment_scores)\n",
        "# Create a dummy technical_data DataFrame\n",
        "# data = {\n",
        "#     'Open': [100, 101, 102, 103, 104],\n",
        "#     'High': [102, 103, 104, 105, 106],\n",
        "#     'Low': [99, 100, 101, 102, 103],\n",
        "#     'Close': [101, 102, 103, 104, 105],\n",
        "#     'Volume': [1000, 1100, 1050, 1200, 1150],\n",
        "#     'RSI_14': [40, 45, 50, 55, 60], # Example RSI values\n",
        "#     'MACD_12_26_9': [1, 1.5, 2, 2.5, 3], # Example MACD values\n",
        "#     'MACDH_12_26_9': [0.1, 0.2, 0.3, 0.4, 0.5], # Example MACDH values\n",
        "#     'MACDS_12_26_9': [0.9, 1.3, 1.7, 2.1, 2.5], # Example MACDS values\n",
        "#     'SMA_20': [100.5, 101.2, 102.1, 103.0, 104.0], # Example SMA_20 values\n",
        "#     'SMA_50': [99.0, 99.5, 100.0, 100.5, 101.0] # Example SMA_50 values\n",
        "# }\n",
        "# dummy_tech_df = pd.DataFrame(data)\n",
        "\n",
        "# Create a dummy sentiment_scores dictionary\n",
        "# dummy_sentiment = {'neg': 0.1, 'neu': 0.7, 'pos': 0.2, 'compound': 0.3}\n",
        "\n",
        "# Generate signal\n",
        "# trading_signal = generate_trading_signal(dummy_tech_df, dummy_sentiment)\n",
        "# print(f\"\\nGenerated Trading Signal: {trading_signal}\")\n",
        "\n",
        "# Example with negative sentiment and bearish technicals\n",
        "# data_bearish = {\n",
        "#     'Open': [105, 104, 103, 102, 101],\n",
        "#     'High': [106, 105, 104, 103, 102],\n",
        "#     'Low': [104, 103, 102, 101, 100],\n",
        "#     'Close': [104, 103, 102, 101, 100],\n",
        "#     'Volume': [1100, 1200, 1150, 1300, 1250],\n",
        "#     'RSI_14': [60, 55, 50, 45, 40], # Example RSI values\n",
        "#     'MACD_12_26_9': [3, 2.5, 2, 1.5, 1], # Example MACD values\n",
        "#     'MACDH_12_26_9': [0.5, 0.4, 0.3, 0.2, 0.1], # Example MACDH values\n",
        "#     'MACDS_12_26_9': [2.5, 2.1, 1.7, 1.3, 0.9], # Example MACDS values\n",
        "#     'SMA_20': [104.0, 103.0, 102.1, 101.2, 100.5], # Example SMA_20 values\n",
        "#     'SMA_50': [101.0, 100.5, 100.0, 99.5, 99.0] # Example SMA_50 values\n",
        "# }\n",
        "# dummy_tech_df_bearish = pd.DataFrame(data_bearish)\n",
        "# dummy_sentiment_negative = {'neg': 0.4, 'neu': 0.5, 'pos': 0.1, 'compound': -0.2}\n",
        "\n",
        "# trading_signal_bearish = generate_trading_signal(dummy_tech_df_bearish, dummy_sentiment_negative)\n",
        "# print(f\"\\nGenerated Trading Signal (Bearish): {trading_signal_bearish}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b12625d"
      },
      "source": [
        "## Risk management\n",
        "\n",
        "### Subtask:\n",
        "Develop functions to calculate suggested position size, stop-loss levels, and target profit prices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "286c4d2c"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the functions for calculating position size, stop-loss, and target profit as requested in the subtask instructions, including error handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "33aa27b9"
      },
      "outputs": [],
      "source": [
        "def calculate_position_size(total_capital: float, risk_percentage: float, stop_loss_price: float, entry_price: float) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the suggested number of shares to trade based on capital, risk, and stop-loss.\n",
        "\n",
        "    Args:\n",
        "        total_capital: Total trading capital available.\n",
        "        risk_percentage: Percentage of total capital to risk per trade (as a decimal, e.g., 0.01 for 1%).\n",
        "        stop_loss_price: The price at which the stop-loss is set.\n",
        "        entry_price: The price at which the trade is entered.\n",
        "\n",
        "    Returns:\n",
        "        The suggested number of shares to trade, or 0 if inputs are invalid.\n",
        "    \"\"\"\n",
        "    if not isinstance(total_capital, (int, float)) or total_capital <= 0:\n",
        "        print(\"Error: Total capital must be a positive number.\")\n",
        "        return 0\n",
        "\n",
        "    if not isinstance(risk_percentage, (int, float)) or not 0 < risk_percentage <= 1:\n",
        "        print(\"Error: Risk percentage must be between 0 (exclusive) and 1 (inclusive).\")\n",
        "        return 0\n",
        "\n",
        "    if not isinstance(stop_loss_price, (int, float)) or stop_loss_price <= 0:\n",
        "        print(\"Error: Stop-loss price must be a positive number.\")\n",
        "        return 0\n",
        "\n",
        "    if not isinstance(entry_price, (int, float)) or entry_price <= 0:\n",
        "        print(\"Error: Entry price must be a positive number.\")\n",
        "        return 0\n",
        "\n",
        "    if (entry_price > stop_loss_price and entry_price - stop_loss_price <= 0) or \\\n",
        "       (entry_price < stop_loss_price and stop_loss_price - entry_price <= 0):\n",
        "        print(\"Error: Stop-loss price is at or above/below the entry price, resulting in zero or negative risk per share.\")\n",
        "        return 0\n",
        "\n",
        "    # Calculate the amount of capital to risk\n",
        "    risk_amount = total_capital * risk_percentage\n",
        "\n",
        "    # Calculate the risk per share\n",
        "    risk_per_share = abs(entry_price - stop_loss_price)\n",
        "\n",
        "    # Calculate the number of shares\n",
        "    if risk_per_share > 0:\n",
        "        suggested_shares = risk_amount / risk_per_share\n",
        "        return suggested_shares\n",
        "    else:\n",
        "        print(\"Error: Risk per share is zero. Cannot calculate position size.\")\n",
        "        return 0\n",
        "\n",
        "\n",
        "def calculate_stop_loss(entry_price: float, risk_tolerance: float, is_long: bool = True) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the suggested stop-loss price.\n",
        "\n",
        "    Args:\n",
        "        entry_price: The price at which the trade is entered.\n",
        "        risk_tolerance: The risk tolerance, either as a percentage (e.g., 0.02 for 2%)\n",
        "                        or a value based on technical indicators (e.g., 2 * ATR).\n",
        "        is_long: Boolean indicating if the position is long (True) or short (False).\n",
        "\n",
        "    Returns:\n",
        "        The suggested stop-loss price, or 0 if inputs are invalid.\n",
        "    \"\"\"\n",
        "    if not isinstance(entry_price, (int, float)) or entry_price <= 0:\n",
        "        print(\"Error: Entry price must be a positive number.\")\n",
        "        return 0\n",
        "\n",
        "    if not isinstance(risk_tolerance, (int, float)) or risk_tolerance < 0:\n",
        "        print(\"Error: Risk tolerance must be a non-negative number.\")\n",
        "        return 0\n",
        "\n",
        "    try:\n",
        "        if is_long:\n",
        "            # For a long position, stop-loss is below entry price\n",
        "            if 0 < risk_tolerance < 1: # Assume risk_tolerance is a percentage\n",
        "                 stop_loss = entry_price * (1 - risk_tolerance)\n",
        "            else: # Assume risk_tolerance is a value\n",
        "                 stop_loss = entry_price - risk_tolerance\n",
        "        else: # Short position\n",
        "             # For a short position, stop-loss is above entry price\n",
        "            if 0 < risk_tolerance < 1: # Assume risk_tolerance is a percentage\n",
        "                 stop_loss = entry_price * (1 + risk_tolerance)\n",
        "            else: # Assume risk_tolerance is a value\n",
        "                 stop_loss = entry_price + risk_tolerance\n",
        "\n",
        "        return stop_loss\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating stop-loss: {e}\")\n",
        "        return 0\n",
        "\n",
        "\n",
        "def calculate_target_profit(entry_price: float, target_profit_factor: float, is_long: bool = True) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the suggested target profit price.\n",
        "\n",
        "    Args:\n",
        "        entry_price: The price at which the trade is entered.\n",
        "        target_profit_factor: A factor to determine the target profit (e.g., a risk/reward ratio like 2 for 1:2).\n",
        "                              This is multiplied by the risk per share.\n",
        "        is_long: Boolean indicating if the position is long (True) or short (False).\n",
        "\n",
        "    Returns:\n",
        "        The suggested target profit price, or 0 if inputs are invalid.\n",
        "    \"\"\"\n",
        "    if not isinstance(entry_price, (int, float)) or entry_price <= 0:\n",
        "        print(\"Error: Entry price must be a positive number.\")\n",
        "        return 0\n",
        "\n",
        "    if not isinstance(target_profit_factor, (int, float)) or target_profit_factor <= 0:\n",
        "        print(\"Error: Target profit factor must be a positive number.\")\n",
        "        return 0\n",
        "\n",
        "    try:\n",
        "        # This calculation requires a stop-loss to determine risk per share.\n",
        "        # For simplicity here, we'll assume the target_profit_factor is applied\n",
        "        # directly to the entry price or a calculated risk amount.\n",
        "        # A more robust implementation would likely use the calculated stop-loss\n",
        "        # to determine the risk per share and then apply the risk/reward ratio.\n",
        "\n",
        "        # Simple approach: apply factor as a percentage increase/decrease\n",
        "        if is_long:\n",
        "            target_profit = entry_price * (1 + target_profit_factor)\n",
        "        else: # Short position\n",
        "             target_profit = entry_price * (1 - target_profit_factor)\n",
        "\n",
        "        return target_profit\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating target profit: {e}\")\n",
        "        return 0\n",
        "\n",
        "# Example Usage (optional, for testing)\n",
        "# total_capital = 10000\n",
        "# risk_percentage = 0.01 # Risk 1% of capital\n",
        "# entry_price = 50.0\n",
        "# stop_loss_price = 49.5 # Risk 0.5 per share\n",
        "\n",
        "# suggested_shares = calculate_position_size(total_capital, risk_percentage, stop_loss_price, entry_price)\n",
        "# print(f\"Suggested shares: {suggested_shares}\")\n",
        "\n",
        "# entry_price = 100.0\n",
        "# risk_tolerance_percentage = 0.02 # 2% risk tolerance\n",
        "# risk_tolerance_value = 2.0 # Risk tolerance of 2 units below entry\n",
        "\n",
        "# stop_loss_pct = calculate_stop_loss(entry_price, risk_tolerance_percentage, is_long=True)\n",
        "# print(f\"Stop-loss (percentage): {stop_loss_pct}\")\n",
        "\n",
        "# stop_loss_value = calculate_stop_loss(entry_price, risk_tolerance_value, is_long=True)\n",
        "# print(f\"Stop-loss (value): {stop_loss_value}\")\n",
        "\n",
        "# entry_price = 100.0\n",
        "# target_profit_factor = 0.05 # 5% target profit\n",
        "# target_profit_rr = 2.0 # Risk/Reward ratio of 1:2 (requires risk per share)\n",
        "\n",
        "# target_profit_pct = calculate_target_profit(entry_price, target_profit_factor, is_long=True)\n",
        "# print(f\"Target profit (percentage factor): {target_profit_pct}\")\n",
        "\n",
        "# Note: Calculating target profit based on risk/reward ratio would require\n",
        "# the stop-loss price to determine the risk per share.\n",
        "# Example using a hypothetical risk_per_share of 0.5:\n",
        "# risk_per_share_example = 0.5\n",
        "# target_profit_rr_calc = entry_price + (risk_per_share_example * target_profit_rr)\n",
        "# print(f\"Target profit (Risk/Reward 1:2, risk=0.5): {target_profit_rr_calc}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7b1570b"
      },
      "source": [
        "## Trading infrastructure\n",
        "\n",
        "### Subtask:\n",
        "Set up the framework for connecting to brokerage APIs (starting with Alpaca) for real-time trade execution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35171504"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary library and define the functions to initialize the Alpaca API and check the connection status with basic error handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2b69281d"
      },
      "outputs": [],
      "source": [
        "import alpaca_trade_api as tradeapi\n",
        "import os\n",
        "\n",
        "def initialize_alpaca_api() -> tradeapi.REST:\n",
        "    \"\"\"\n",
        "    Initializes and returns an Alpaca API object.\n",
        "\n",
        "    Loads API keys from environment variables and includes basic error handling.\n",
        "\n",
        "    Returns:\n",
        "        An initialized Alpaca API REST object, or None if API keys are not available.\n",
        "    \"\"\"\n",
        "    # Ensure API keys are loaded from environment variables\n",
        "    # Assuming alpaca_api_key_id and alpaca_api_secret_key are already loaded\n",
        "    # in a previous step (e.g., from a .env file)\n",
        "\n",
        "    api_key_id = os.getenv('APCA_API_KEY_ID')\n",
        "    api_secret_key = os.getenv('APCA_API_SECRET_KEY')\n",
        "    base_url = os.getenv('APCA_API_BASE_URL', 'https://paper-api.alpaca.markets') # Default to paper trading URL\n",
        "\n",
        "    if not api_key_id or not api_secret_key:\n",
        "        print(\"Alpaca API keys (APCA_API_KEY_ID and APCA_API_SECRET_KEY) not found in environment variables.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        api = tradeapi.REST(api_key_id, api_secret_key, base_url, api_version='v2')\n",
        "        print(\"Alpaca API object initialized.\")\n",
        "        return api\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Alpaca API: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_alpaca_connection(api: tradeapi.REST) -> bool:\n",
        "    \"\"\"\n",
        "    Checks the status of the Alpaca API connection by fetching account details.\n",
        "\n",
        "    Args:\n",
        "        api: An initialized Alpaca API REST object.\n",
        "\n",
        "    Returns:\n",
        "        True if the connection is successful, False otherwise.\n",
        "    \"\"\"\n",
        "    if api is None:\n",
        "        print(\"Alpaca API object is not initialized.\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        account = api.get_account()\n",
        "        print(\"Alpaca API connection successful. Account details fetched.\")\n",
        "        # You can optionally print some account details for verification\n",
        "        # print(f\"Account Status: {account.status}\")\n",
        "        # print(f\"Equity: {account.equity}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking Alpaca API connection: {e}\")\n",
        "        return False\n",
        "\n",
        "# Example Usage (optional, for testing)\n",
        "# alpaca_api = initialize_alpaca_api()\n",
        "# if alpaca_api:\n",
        "#     connection_status = check_alpaca_connection(alpaca_api)\n",
        "#     print(f\"Alpaca connection status: {connection_status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c772c92a"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates a missing dependency for `alpha_vantage`, which is required by `alpaca-trade-api`. Install the `alpha-vantage` library to resolve this.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YEmgtnWvNquu"
      },
      "outputs": [],
      "source": [
        "%pip install alpha-vantage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84abecdc"
      },
      "source": [
        "**Reasoning**:\n",
        "Although the previous command indicated the library was already installed, the traceback suggests a specific module is missing. This might be due to an incomplete installation or a version conflict. Re-running the installation with force-reinstall might fix this. Then, retry the code to initialize and check the Alpaca API connection.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c0178c63"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --force-reinstall alpha-vantage alpaca-trade-api\n",
        "\n",
        "import alpaca_trade_api as tradeapi\n",
        "import os\n",
        "\n",
        "def initialize_alpaca_api() -> tradeapi.REST:\n",
        "    \"\"\"\n",
        "    Initializes and returns an Alpaca API object.\n",
        "\n",
        "    Loads API keys from environment variables and includes basic error handling.\n",
        "\n",
        "    Returns:\n",
        "        An initialized Alpaca API REST object, or None if API keys are not available.\n",
        "    \"\"\"\n",
        "    # Ensure API keys are loaded from environment variables\n",
        "    # Assuming alpaca_api_key_id and alpaca_api_secret_key are already loaded\n",
        "    # in a previous step (e.g., from a .env file)\n",
        "\n",
        "    api_key_id = os.getenv('APCA_API_KEY_ID')\n",
        "    api_secret_key = os.getenv('APCA_API_SECRET_KEY')\n",
        "    base_url = os.getenv('APCA_API_BASE_URL', 'https://paper-api.alpaca.markets') # Default to paper trading URL\n",
        "\n",
        "    if not api_key_id or not api_secret_key:\n",
        "        print(\"Alpaca API keys (APCA_API_KEY_ID and APCA_API_SECRET_KEY) not found in environment variables.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        api = tradeapi.REST(api_key_id, api_secret_key, base_url, api_version='v2')\n",
        "        print(\"Alpaca API object initialized.\")\n",
        "        return api\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Alpaca API: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_alpaca_connection(api: tradeapi.REST) -> bool:\n",
        "    \"\"\"\n",
        "    Checks the status of the Alpaca API connection by fetching account details.\n",
        "\n",
        "    Args:\n",
        "        api: An initialized Alpaca API REST object.\n",
        "\n",
        "    Returns:\n",
        "        True if the connection is successful, False otherwise.\n",
        "    \"\"\"\n",
        "    if api is None:\n",
        "        print(\"Alpaca API object is not initialized.\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        account = api.get_account()\n",
        "        print(\"Alpaca API connection successful. Account details fetched.\")\n",
        "        # You can optionally print some account details for verification\n",
        "        # print(f\"Account Status: {account.status}\")\n",
        "        # print(f\"Equity: {account.equity}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking Alpaca API connection: {e}\")\n",
        "        return False\n",
        "\n",
        "# Example Usage (optional, for testing)\n",
        "# alpaca_api = initialize_alpaca_api()\n",
        "# if alpaca_api:\n",
        "#     connection_status = check_alpaca_connection(alpaca_api)\n",
        "#     print(f\"Alpaca connection status: {connection_status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e314c7cc"
      },
      "source": [
        "## Trading infrastructure\n",
        "\n",
        "### Subtask:\n",
        "Retry setting up the framework for connecting to brokerage APIs (starting with Alpaca) for real-time trade execution.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "128a68ba"
      },
      "source": [
        "**Reasoning**:\n",
        "Attempt to import the alpaca_trade_api library again, this time with a try-except block to gracefully handle the ImportError as per the instructions. Keep the previously defined functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "49b853a3"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import alpaca_trade_api as tradeapi\n",
        "    print(\"alpaca_trade_api imported successfully.\")\n",
        "except ImportError as e:\n",
        "    print(f\"ImportError: {e}\")\n",
        "    print(\"Alpaca API functionality is unavailable due to import issues.\")\n",
        "    tradeapi = None # Set tradeapi to None if import fails\n",
        "\n",
        "# Keep the previously defined functions\n",
        "def initialize_alpaca_api() -> tradeapi.REST:\n",
        "    \"\"\"\n",
        "    Initializes and returns an Alpaca API object.\n",
        "\n",
        "    Loads API keys from environment variables and includes basic error handling.\n",
        "\n",
        "    Returns:\n",
        "        An initialized Alpaca API REST object, or None if API keys are not available or import failed.\n",
        "    \"\"\"\n",
        "    if tradeapi is None:\n",
        "        print(\"Alpaca API library not imported.\")\n",
        "        return None\n",
        "\n",
        "    api_key_id = os.getenv('APCA_API_KEY_ID')\n",
        "    api_secret_key = os.getenv('APCA_API_SECRET_KEY')\n",
        "    base_url = os.getenv('APCA_API_BASE_URL', 'https://paper-api.alpaca.markets') # Default to paper trading URL\n",
        "\n",
        "    if not api_key_id or not api_secret_key:\n",
        "        print(\"Alpaca API keys (APCA_API_KEY_ID and APCA_API_SECRET_KEY) not found in environment variables.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        api = tradeapi.REST(api_key_id, api_secret_key, base_url, api_version='v2')\n",
        "        print(\"Alpaca API object initialized.\")\n",
        "        return api\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing Alpaca API: {e}\")\n",
        "        return None\n",
        "\n",
        "def check_alpaca_connection(api: tradeapi.REST) -> bool:\n",
        "    \"\"\"\n",
        "    Checks the status of the Alpaca API connection by fetching account details.\n",
        "\n",
        "    Args:\n",
        "        api: An initialized Alpaca API REST object.\n",
        "\n",
        "    Returns:\n",
        "        True if the connection is successful, False otherwise.\n",
        "    \"\"\"\n",
        "    if api is None:\n",
        "        print(\"Alpaca API object is not initialized.\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        account = api.get_account()\n",
        "        print(\"Alpaca API connection successful. Account details fetched.\")\n",
        "        # You can optionally print some account details for verification\n",
        "        # print(f\"Account Status: {account.status}\")\n",
        "        # print(f\"Equity: {account.equity}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking Alpaca API connection: {e}\")\n",
        "        return False\n",
        "\n",
        "# Example Usage (optional, for testing)\n",
        "# alpaca_api = initialize_alpaca_api()\n",
        "# if alpaca_api:\n",
        "#     connection_status = check_alpaca_connection(alpaca_api)\n",
        "#     print(f\"Alpaca connection status: {connection_status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "197567b2"
      },
      "source": [
        "## Machine learning integration\n",
        "\n",
        "### Subtask:\n",
        "Explore and implement machine learning models for predictive modeling and pattern recognition.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fedc9e5a"
      },
      "source": [
        "**Reasoning**:\n",
        "Import necessary machine learning modules from sklearn and prepare the data by adding the target variable for prediction based on historical price movement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "284fe942"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assume 'historical_data' DataFrame is available from the data acquisition step\n",
        "# and 'df_with_indicators' from the stock analysis step\n",
        "# If not available, create a dummy DataFrame for demonstration\n",
        "if 'df_with_indicators' not in locals() or df_with_indicators.empty:\n",
        "    print(\"Using dummy data as 'df_with_indicators' was not found or is empty.\")\n",
        "    # Create a dummy technical_data DataFrame\n",
        "    data = {\n",
        "        'Open': [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n",
        "        'High': [102, 103, 104, 105, 106, 107, 108, 109, 110, 111],\n",
        "        'Low': [99, 100, 101, 102, 103, 104, 105, 106, 107, 108],\n",
        "        'Close': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
        "        'Volume': [1000, 1100, 1050, 1200, 1150, 1250, 1300, 1200, 1350, 1400],\n",
        "        'RSI_14': [40, 45, 50, 55, 60, 65, 70, 68, 63, 68], # Example RSI values\n",
        "        'MACD_12_26_9': [1, 1.5, 2, 2.5, 3, 3.5, 4, 3.8, 3.5, 3.7], # Example MACD values\n",
        "        'MACDH_12_26_9': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.5, 0.3, 0.4], # Example MACDH values\n",
        "        'MACDS_12_26_9': [0.9, 1.3, 1.7, 2.1, 2.5, 2.9, 3.3, 3.3, 3.2, 3.3], # Example MACDS values\n",
        "        'SMA_20': [100.5, 101.2, 102.1, 103.0, 104.0, 105.0, 106.0, 106.9, 107.7, 108.6], # Example SMA_20 values\n",
        "        'SMA_50': [99.0, 99.5, 100.0, 100.5, 101.0, 101.6, 102.3, 103.1, 103.9, 104.8] # Example SMA_50 values\n",
        "    }\n",
        "    df_with_indicators = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Prepare the target variable: 1 if next day's close is higher, 0 otherwise\n",
        "df_with_indicators['Target'] = (df_with_indicators['Close'].shift(-1) > df_with_indicators['Close']).astype(int)\n",
        "\n",
        "# Drop the last row as it will have NaN for the Target\n",
        "df_with_indicators.dropna(subset=['Target'], inplace=True)\n",
        "\n",
        "display(df_with_indicators.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd49b975"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed due to an ImportError related to numpy and scipy, likely caused by incompatible versions installed by previous steps. To resolve this, I need to reinstall and potentially downgrade numpy and scipy to versions compatible with sklearn. After resolving the import issue, I will proceed with preparing the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OVpUfk9hOaKr"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --force-reinstall numpy==1.26.4 scipy==1.12.0 scikit-learn==1.4.1\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assume 'historical_data' DataFrame is available from the data acquisition step\n",
        "# and 'df_with_indicators' from the stock analysis step\n",
        "# If not available, create a dummy DataFrame for demonstration\n",
        "if 'df_with_indicators' not in locals() or df_with_indicators.empty:\n",
        "    print(\"Using dummy data as 'df_with_indicators' was not found or is empty.\")\n",
        "    # Create a dummy technical_data DataFrame\n",
        "    data = {\n",
        "        'Open': [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n",
        "        'High': [102, 103, 104, 105, 106, 107, 108, 109, 110, 111],\n",
        "        'Low': [99, 100, 101, 102, 103, 104, 105, 106, 107, 108],\n",
        "        'Close': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
        "        'Volume': [1000, 1100, 1050, 1200, 1150, 1250, 1300, 1200, 1350, 1400],\n",
        "        'RSI_14': [40, 45, 50, 55, 60, 65, 70, 68, 63, 68], # Example RSI values\n",
        "        'MACD_12_26_9': [1, 1.5, 2, 2.5, 3, 3.5, 4, 3.8, 3.5, 3.7], # Example MACD values\n",
        "        'MACDH_12_26_9': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.5, 0.3, 0.4], # Example MACDH values\n",
        "        'MACDS_12_26_9': [0.9, 1.3, 1.7, 2.1, 2.5, 2.9, 3.3, 3.3, 3.2, 3.3], # Example MACDS values\n",
        "        'SMA_20': [100.5, 101.2, 102.1, 103.0, 104.0, 105.0, 106.0, 106.9, 107.7, 108.6], # Example SMA_20 values\n",
        "        'SMA_50': [99.0, 99.5, 100.0, 100.5, 101.0, 101.6, 102.3, 103.1, 103.9, 104.8] # Example SMA_50 values\n",
        "    }\n",
        "    df_with_indicators = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Prepare the target variable: 1 if next day's close is higher, 0 otherwise\n",
        "df_with_indicators['Target'] = (df_with_indicators['Close'].shift(-1) > df_with_indicators['Close']).astype(int)\n",
        "\n",
        "# Drop the last row as it will have NaN for the Target\n",
        "df_with_indicators.dropna(subset=['Target'], inplace=True)\n",
        "\n",
        "display(df_with_indicators.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8c7a08c"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous command failed because the specified versions of numpy and scikit-learn are not compatible with the current Python version (3.12). I will try installing compatible versions of numpy, scipy, and scikit-learn to resolve the import error and then proceed with preparing the data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SOMD295HOhjS"
      },
      "outputs": [],
      "source": [
        "%pip install --upgrade --force-reinstall numpy scipy scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Assume 'historical_data' DataFrame is available from the data acquisition step\n",
        "# and 'df_with_indicators' from the stock analysis step\n",
        "# If not available, create a dummy DataFrame for demonstration\n",
        "if 'df_with_indicators' not in locals() or df_with_indicators.empty:\n",
        "    print(\"Using dummy data as 'df_with_indicators' was not found or is empty.\")\n",
        "    # Create a dummy technical_data DataFrame\n",
        "    data = {\n",
        "        'Open': [100, 101, 102, 103, 104, 105, 106, 107, 108, 109],\n",
        "        'High': [102, 103, 104, 105, 106, 107, 108, 109, 110, 111],\n",
        "        'Low': [99, 100, 101, 102, 103, 104, 105, 106, 107, 108],\n",
        "        'Close': [101, 102, 103, 104, 105, 106, 107, 108, 109, 110],\n",
        "        'Volume': [1000, 1100, 1050, 1200, 1150, 1250, 1300, 1200, 1350, 1400],\n",
        "        'RSI_14': [40, 45, 50, 55, 60, 65, 70, 68, 63, 68], # Example RSI values\n",
        "        'MACD_12_26_9': [1, 1.5, 2, 2.5, 3, 3.5, 4, 3.8, 3.5, 3.7], # Example MACD values\n",
        "        'MACDH_12_26_9': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.5, 0.3, 0.4], # Example MACDH values\n",
        "        'MACDS_12_26_9': [0.9, 1.3, 1.7, 2.1, 2.5, 2.9, 3.3, 3.3, 3.2, 3.3], # Example MACDS values\n",
        "        'SMA_20': [100.5, 101.2, 102.1, 103.0, 104.0, 105.0, 106.0, 106.9, 107.7, 108.6], # Example SMA_20 values\n",
        "        'SMA_50': [99.0, 99.5, 100.0, 100.5, 101.0, 101.6, 102.3, 103.1, 103.9, 104.8] # Example SMA_50 values\n",
        "    }\n",
        "    df_with_indicators = pd.DataFrame(data)\n",
        "\n",
        "\n",
        "# Prepare the target variable: 1 if next day's close is higher, 0 otherwise\n",
        "df_with_indicators['Target'] = (df_with_indicators['Close'].shift(-1) > df_with_indicators['Close']).astype(int)\n",
        "\n",
        "# Drop the last row as it will have NaN for the Target\n",
        "df_with_indicators.dropna(subset=['Target'], inplace=True)\n",
        "\n",
        "display(df_with_indicators.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58e9314d"
      },
      "source": [
        "## Real-time data handling\n",
        "\n",
        "### Subtask:\n",
        "Implement WebSocket connections and asynchronous data handling for processing real-time data efficiently.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "994e3f93"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary libraries for WebSocket connections and asynchronous operations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dbc5429a"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import websockets\n",
        "import json # Import json for processing messages\n",
        "import os # Ensure os is imported to get the API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7545e3c6"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the asynchronous function to connect to the Finnhub WebSocket, establish the connection, send subscription messages, and process received messages with basic error handling.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2d90b495"
      },
      "outputs": [],
      "source": [
        "async def connect_finnhub_websocket(api_key: str, symbols: list):\n",
        "    \"\"\"\n",
        "    Connects to the Finnhub WebSocket and subscribes to real-time trade data for given symbols.\n",
        "\n",
        "    Args:\n",
        "        api_key: Your Finnhub API key.\n",
        "        symbols: A list of stock symbols (e.g., [\"AAPL\", \"MSFT\"]).\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        print(\"Finnhub API key is not provided.\")\n",
        "        return\n",
        "\n",
        "    # Construct the WebSocket URL\n",
        "    # Using the trade data endpoint as an example\n",
        "    uri = f\"wss://ws.finnhub.io?token={api_key}\"\n",
        "\n",
        "    print(f\"Connecting to WebSocket at {uri}...\")\n",
        "\n",
        "    try:\n",
        "        async with websockets.connect(uri) as websocket:\n",
        "            print(\"WebSocket connection established.\")\n",
        "\n",
        "            # Send subscription messages for each symbol\n",
        "            for symbol in symbols:\n",
        "                subscribe_message = {\"type\": \"subscribe\", \"symbol\": symbol}\n",
        "                await websocket.send(json.dumps(subscribe_message))\n",
        "                print(f\"Sent subscription request for {symbol}\")\n",
        "\n",
        "            # Continuously receive and process messages\n",
        "            while True:\n",
        "                try:\n",
        "                    message = await websocket.recv()\n",
        "                    # Process the received message\n",
        "                    # For now, just print it\n",
        "                    print(f\"Received message: {message}\")\n",
        "\n",
        "                    # You might want to parse the message (it's likely JSON)\n",
        "                    # data = json.loads(message)\n",
        "                    # Handle different message types (e.g., 'trade', 'ping')\n",
        "                    # if data.get('type') == 'trade':\n",
        "                    #     print(f\"Trade data: {data}\")\n",
        "                    # elif data.get('type') == 'ping':\n",
        "                    #      await websocket.send('{\"type\":\"pong\"}') # Respond to ping\n",
        "\n",
        "\n",
        "                except websockets.exceptions.ConnectionClosedOK:\n",
        "                    print(\"WebSocket connection closed normally.\")\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    print(f\"Error receiving or processing message: {e}\")\n",
        "                    # Optionally attempt to reconnect or handle specific errors\n",
        "                    break # Exit loop on error for simplicity\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error connecting to WebSocket: {e}\")\n",
        "\n",
        "\n",
        "# Define example symbols and get API key from environment\n",
        "# Assuming finnhub_api_key is loaded from environment variables in a previous step\n",
        "example_symbols = [\"AAPL\", \"MSFT\"]\n",
        "finnhub_api_key_websocket = os.getenv('FINNHUB_API_KEY') # Use the same key\n",
        "\n",
        "# Run the asynchronous function\n",
        "# asyncio.run(connect_finnhub_websocket(finnhub_api_key_websocket, example_symbols))\n",
        "\n",
        "print(\"Asynchronous function 'connect_finnhub_websocket' defined.\")\n",
        "print(\"Example usage is commented out.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ee26276"
      },
      "source": [
        "**Reasoning**:\n",
        "The asynchronous function is defined. Now, use `asyncio.run()` to start the asynchronous function with example symbols.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f0fedc6e"
      },
      "outputs": [],
      "source": [
        "# Ensure finnhub_api_key_websocket is available from the previous step\n",
        "if 'finnhub_api_key_websocket' not in locals() or finnhub_api_key_websocket is None:\n",
        "    print(\"Finnhub API key not found. Cannot run WebSocket connection example.\")\n",
        "else:\n",
        "    print(\"Running WebSocket connection example. This will attempt to connect and print messages.\")\n",
        "    print(\"Press Ctrl+C to stop the connection.\")\n",
        "    try:\n",
        "        asyncio.run(connect_finnhub_websocket(finnhub_api_key_websocket, example_symbols))\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nWebSocket connection stopped by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during asyncio run: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bf7daa9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous attempt to run `asyncio.run()` failed because it was called from within an already running event loop in the Jupyter environment. The correct way to run an async function in Jupyter is by awaiting it directly if in an async cell, or using `nest_asyncio` if in a standard cell and needing `asyncio.run`. Since we are in a standard cell and the previous code defined the async function, we need to adjust how it's run to work within the notebook environment. The simplest way in many modern Jupyter environments is to just `await` the function call directly if the cell supports it, or use `nest_asyncio`. Given the error, using `nest_asyncio` is the most reliable approach to allow `asyncio.run` in this context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "WDEjINWnPABa"
      },
      "outputs": [],
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Ensure finnhub_api_key_websocket is available from the previous step\n",
        "if 'finnhub_api_key_websocket' not in locals() or finnhub_api_key_websocket is None:\n",
        "    print(\"Finnhub API key not found. Cannot run WebSocket connection example.\")\n",
        "else:\n",
        "    print(\"Running WebSocket connection example using nest_asyncio. This will attempt to connect and print messages.\")\n",
        "    print(\"Press Ctrl+C to stop the connection.\")\n",
        "    try:\n",
        "        # asyncio.run() is now safe to call within the notebook\n",
        "        asyncio.run(connect_finnhub_websocket(finnhub_api_key_websocket, example_symbols))\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"\\nWebSocket connection stopped by user.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during asyncio run: {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c2b31f6"
      },
      "source": [
        "## Dashboard and monitoring (conceptual)\n",
        "\n",
        "### Subtask:\n",
        "Outline the requirements and potential technologies for building an interactive web-based dashboard, although the actual implementation might be outside the scope of a single notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "706497a4"
      },
      "source": [
        "**Reasoning**:\n",
        "Outline the requirements, potential technologies, and a conceptual architecture for the dashboard as requested by the subtask instructions. This will involve describing the features, listing potential technologies, and outlining the interactions with other components.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "e872e5c0"
      },
      "outputs": [],
      "source": [
        "# 1. Describe the key features and functionalities of the ApexAMMO dashboard\n",
        "\n",
        "print(\"Key Features and Functionalities for the ApexAMMO Dashboard:\")\n",
        "print(\"- **Real-time Portfolio Value:** Display the current total value of the user's trading portfolio.\")\n",
        "print(\"- **Open Positions:** List all currently open trades with details like symbol, quantity, entry price, current price, and profit/loss.\")\n",
        "print(\"- **Trade History:** Show a log of past trades with execution details, outcomes, and performance metrics.\")\n",
        "print(\"- **Real-time Data Feeds:** Visualize real-time price data (candlestick charts), volume, and potentially order book data.\")\n",
        "print(\"- **Sentiment Indicators:** Display aggregated market sentiment derived from news analysis.\")\n",
        "print(\"- **Trading Signals:** Clearly present the generated BUY/SELL/HOLD signals for monitored assets.\")\n",
        "print(\"- **Performance Metrics:** Show key performance indicators (e.g., win rate, average profit per trade, total profit/loss, drawdown).\")\n",
        "print(\"- **Account Information:** Display account details from the broker (e.g., buying power, cash balance).\")\n",
        "print(\"- **Alerts and Notifications:** Provide customizable alerts for trading signals, price movements, or portfolio changes.\")\n",
        "print(\"- **Configuration Settings:** Allow users to configure trading parameters, risk tolerance, and monitored assets.\")\n",
        "print(\"- **Logging and Error Monitoring:** Display logs and highlight any errors or warnings from the trading agent.\")\n",
        "print(\"\\n---\")\n",
        "\n",
        "# 2. Identify potential technologies for building the dashboard\n",
        "\n",
        "print(\"Potential Technologies for Building the Dashboard:\")\n",
        "\n",
        "print(\"\\nFront-end Frameworks/Libraries:\")\n",
        "print(\"- **Dash:** A Python framework for building analytical web applications without requiring JavaScript, suitable for data scientists.\")\n",
        "print(\"- **Plotly:** A graphing library that integrates well with Dash and can be used for creating interactive plots.\")\n",
        "print(\"- **Streamlit:** Another Python framework for quickly building and sharing data apps, often simpler for rapid prototyping.\")\n",
        "print(\"- **React / Vue.js:** Popular JavaScript frameworks for building complex, highly interactive user interfaces.\")\n",
        "\n",
        "print(\"\\nBack-end Frameworks:\")\n",
        "print(\"- **Flask:** A lightweight Python web framework, suitable for smaller applications and APIs.\")\n",
        "print(\"- **Django:** A more full-featured Python web framework, suitable for larger, more complex applications.\")\n",
        "print(\"- **FastAPI:** A modern, fast (high-performance) web framework for building APIs with Python, based on standard Python type hints.\")\n",
        "\n",
        "print(\"\\nData Visualization Libraries:\")\n",
        "print(\"- **Plotly:** (Mentioned above) Excellent for interactive web-based plots.\")\n",
        "print(\"- **Matplotlib / Seaborn:** Can be used for generating static plots, potentially rendered server-side and displayed on the dashboard.\")\n",
        "print(\"- **Bokeh:** Another interactive visualization library for web browsers.\")\n",
        "\n",
        "print(\"\\nOther Considerations:\")\n",
        "print(\"- **WebSocket Libraries:** For real-time data updates (e.g., `websockets` in Python for back-end, browser's native WebSocket API or libraries like `socket.io` for front-end).\")\n",
        "print(\"- **Databases:** To store historical data, trade logs, and user configurations (e.g., PostgreSQL, SQLite).\")\n",
        "print(\"\\n---\")\n",
        "\n",
        "# 3. Outline a high-level conceptual architecture for the dashboard\n",
        "\n",
        "print(\"High-Level Conceptual Architecture for the ApexAMMO Dashboard:\")\n",
        "\n",
        "print(\"\\n[User Browser] <--- HTTP/WebSocket ---> [Dashboard Web Server (Flask/Django/FastAPI + Dash/Streamlit/React/Vue.js)]\")\n",
        "print(\"                               |\")\n",
        "print(\"                               | HTTP/API Calls\")\n",
        "print(\"                               V\")\n",
        "print(\"[ApexAMMO Core Agent (Python Application)]\")\n",
        "print(\"       |       |       |       |       |\")\n",
        "print(\"       |       |       |       |       | (API/Internal Communication)\")\n",
        "print(\"       V       V       V       V       V\")\n",
        "print(\"[Data Acquisition] [Stock Analysis] [Sentiment Analysis] [Trading Signal Generation] [Risk Management] [Trading Infrastructure (Alpaca API)] [Database (Optional)]\")\n",
        "\n",
        "print(\"\\nInteraction Flow:\")\n",
        "print(\"1.  **Real-time Data:** The Dashboard Web Server receives real-time data updates from the ApexAMMO Core Agent (which gets data from sources like Finnhub via WebSockets) using WebSocket connections.\")\n",
        "print(\"2.  **Historical Data & Analysis Results:** The Dashboard Web Server requests historical data, technical analysis results, sentiment analysis results, and trading signals from the ApexAMMO Core Agent via HTTP API calls.\")\n",
        "print(\"3.  **Portfolio & Trade Information:** The Dashboard Web Server queries the ApexAMMO Core Agent (which interacts with the Broker API like Alpaca) to get real-time portfolio value, open positions, and trade history.\")\n",
        "print(\"4.  **Performance Metrics:** The Dashboard Web Server retrieves calculated performance metrics from the ApexAMMO Core Agent (potentially stored in a database).\")\n",
        "print(\"5.  **Configuration:** The Dashboard allows users to update configuration settings which are sent to the ApexAMMO Core Agent (and potentially stored in a database) via API calls.\")\n",
        "print(\"6.  **Logging/Monitoring:** The Dashboard displays logs and error information exposed by the ApexAMMO Core Agent via an API endpoint.\")\n",
        "print(\"7.  **Core Agent Operations:** The ApexAMMO Core Agent runs the main trading logic, acquiring data, performing analysis, generating signals, managing risk, and executing trades through the Trading Infrastructure.\")\n",
        "print(\"8.  **Database (Optional):** A database can be used by the Core Agent to store historical data, trade logs, and configuration, which the Dashboard can then query via the Core Agent or directly (depending on architecture).\")\n",
        "\n",
        "print(\"\\nConceptual Architecture Notes:\")\n",
        "print(\"- The ApexAMMO Core Agent acts as the central hub, processing data, generating signals, and interacting with the broker.\")\n",
        "print(\"- The Dashboard is a separate web application that communicates with the Core Agent to fetch information and display it to the user.\")\n",
        "print(\"- WebSocket is crucial for real-time updates on the dashboard.\")\n",
        "print(\"- REST APIs can be used for requesting historical or less frequently updated information and for sending configuration commands.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26adbeb1"
      },
      "source": [
        "## Logging and error handling\n",
        "\n",
        "### Subtask:\n",
        "Implement robust logging and error handling mechanisms throughout the codebase.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf7c259f"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement robust logging and error handling mechanisms throughout the codebase by importing the logging module, configuring basic logging settings, and modifying previously defined functions with try...except blocks and logging messages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cfdf3d84"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Configure logging\n",
        "# Ensure the logs directory exists\n",
        "if not os.path.exists('logs'):\n",
        "    os.makedirs('logs')\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO, # Set the logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL)\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', # Define the log message format\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"logs/apexammo.log\"), # Log messages to a file\n",
        "        logging.StreamHandler(sys.stdout) # Also print log messages to the console\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Get a logger for the ApexAMMO application\n",
        "logger = logging.getLogger('ApexAMMO')\n",
        "\n",
        "# Modify previously defined functions to include logging and enhanced error handling\n",
        "\n",
        "# Data Acquisition Functions (from subtask 2)\n",
        "def fetch_historical_data(ticker, start_date, end_date):\n",
        "    \"\"\"Fetches historical stock data using yfinance with logging and error handling.\"\"\"\n",
        "    try:\n",
        "        logger.info(f\"Attempting to fetch historical data for {ticker} from {start_date} to {end_date}\")\n",
        "        data = yf.download(ticker, start=start_date, end=end_date)\n",
        "        if data.empty:\n",
        "            logger.warning(f\"No historical data found for ticker: {ticker}\")\n",
        "            return None\n",
        "        logger.info(f\"Successfully fetched historical data for {ticker}. Rows: {len(data)}\")\n",
        "        return data\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error fetching historical data for {ticker}: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "def fetch_realtime_data(ticker):\n",
        "    \"\"\"Fetches real-time stock data using Finnhub with logging and error handling.\"\"\"\n",
        "    if finnhub_client is None:\n",
        "        logger.error(\"Finnhub client is not initialized. Cannot fetch real-time data.\")\n",
        "        return None\n",
        "    try:\n",
        "        logger.info(f\"Attempting to fetch real-time data for {ticker}\")\n",
        "        quote = finnhub_client.quote(ticker)\n",
        "        if quote and 'c' in quote:\n",
        "            logger.info(f\"Successfully fetched real-time data for {ticker}: {quote}\")\n",
        "            return quote\n",
        "        else:\n",
        "            logger.warning(f\"Could not retrieve real-time data for ticker: {ticker}. Response: {quote}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error fetching real-time data for {ticker}: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "def fetch_news_headlines(ticker=None, category=None):\n",
        "    \"\"\"Fetches news headlines using Finnhub with logging and error handling.\"\"\"\n",
        "    if finnhub_client is None:\n",
        "        logger.error(\"Finnhub client is not initialized. Cannot fetch news headlines.\")\n",
        "        return None\n",
        "    try:\n",
        "        if ticker:\n",
        "            logger.info(f\"Attempting to fetch company news for ticker: {ticker}\")\n",
        "            news = finnhub_client.company_news(ticker, _from=\"2023-01-01\", to=\"2023-12-31\")\n",
        "        elif category:\n",
        "            logger.info(f\"Attempting to fetch general news for category: {category}\")\n",
        "            news = finnhub_client.general_news(category=category, min_id=0)\n",
        "        else:\n",
        "            logger.warning(\"Please provide either a ticker or a category for news.\")\n",
        "            return None\n",
        "\n",
        "        if news:\n",
        "            logger.info(f\"Successfully fetched news headlines. Count: {len(news)}\")\n",
        "            return news\n",
        "        else:\n",
        "            logger.warning(f\"No news found for ticker: {ticker} or category: {category}\")\n",
        "            return None\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error fetching news: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "# Stock Analysis Functions (from subtask 3)\n",
        "def calculate_technical_indicators(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Calculates technical indicators with logging and error handling.\n",
        "    \"\"\"\n",
        "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
        "        logger.warning(\"Input to calculate_technical_indicators is not a valid pandas DataFrame or is empty.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "    required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']\n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        logger.error(f\"DataFrame must contain the following columns for technical analysis: {required_cols}\")\n",
        "        return df\n",
        "\n",
        "    try:\n",
        "        logger.info(\"Calculating technical indicators...\")\n",
        "        df.ta.rsi(append=True)\n",
        "        df.ta.macd(append=True)\n",
        "        df.ta.sma(length=20, append=True)\n",
        "        df.ta.sma(length=50, append=True)\n",
        "        logger.info(\"Technical indicators calculated successfully.\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error calculating technical indicators: {e}\", exc_info=True)\n",
        "        return df\n",
        "\n",
        "def determine_market_personality(df: pd.DataFrame) -> str:\n",
        "    \"\"\"\n",
        "    Determines the market personality based on technical indicators with logging and error handling.\n",
        "    \"\"\"\n",
        "    if not isinstance(df, pd.DataFrame) or df.empty:\n",
        "        logger.warning(\"Input to determine_market_personality is not a valid pandas DataFrame or is empty.\")\n",
        "        return 'Undetermined'\n",
        "\n",
        "    try:\n",
        "        logger.info(\"Determining market personality...\")\n",
        "        # Ensure SMAs are available and handle NaNs from calculation\n",
        "        if 'SMA_20' not in df.columns or 'SMA_50' not in df.columns:\n",
        "             logger.warning(\"SMA columns not found in DataFrame for market personality determination.\")\n",
        "             return 'Undetermined'\n",
        "\n",
        "        df['SMA_20'] = df['SMA_20'].fillna(0)\n",
        "        df['SMA_50'] = df['SMA_50'].fillna(0)\n",
        "\n",
        "        personality = 'Undetermined'\n",
        "\n",
        "        if df['SMA_20'].iloc[-1] > df['SMA_50'].iloc[-1] and df['Close'].iloc[-1] > df['SMA_20'].iloc[-1]:\n",
        "            if 'MACDH_12_26_9' in df.columns and df['MACDH_12_26_9'].iloc[-1] > 0:\n",
        "                 personality = 'Trending Up'\n",
        "            elif 'MACDH_12_26_9' not in df.columns:\n",
        "                 personality = 'Trending Up'\n",
        "\n",
        "        elif df['SMA_20'].iloc[-1] < df['SMA_50'].iloc[-1] and df['Close'].iloc[-1] < df['SMA_20'].iloc[-1]:\n",
        "            if 'MACDH_12_26_9' in df.columns and df['MACDH_12_26_9'].iloc[-1] < 0:\n",
        "                personality = 'Trending Down'\n",
        "            elif 'MACDH_12_26_9' not in df.columns:\n",
        "                 personality = 'Trending Down'\n",
        "\n",
        "        if 'RSI_14' in df.columns and 40 < df['RSI_14'].iloc[-1] < 60:\n",
        "             if abs(df['SMA_20'].iloc[-1] - df['SMA_50'].iloc[-1]) / df['SMA_50'].iloc[-1] < 0.02:\n",
        "                 personality = 'Range-Bound'\n",
        "\n",
        "        logger.info(f\"Market personality determined as: {personality}\")\n",
        "        return personality\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error determining market personality: {e}\", exc_info=True)\n",
        "        return 'Undetermined'\n",
        "\n",
        "# Sentiment Analysis Function (from subtask 4)\n",
        "def analyze_sentiment(headline: str) -> dict:\n",
        "    \"\"\"\n",
        "    Analyzes the sentiment of a news headline using NLTK's VADER with logging and error handling.\n",
        "    \"\"\"\n",
        "    if not isinstance(headline, str) or not headline:\n",
        "        logger.warning(\"Input to analyze_sentiment is not a valid string or is empty.\")\n",
        "        return {\"error\": \"Invalid input headline\"}\n",
        "\n",
        "    try:\n",
        "        logger.info(f\"Analyzing sentiment for headline: '{headline[:50]}...'\") # Log snippet\n",
        "        analyzer = SentimentIntensityAnalyzer()\n",
        "        sentiment_scores = analyzer.polarity_scores(headline)\n",
        "        logger.info(f\"Sentiment analysis complete. Scores: {sentiment_scores}\")\n",
        "        return sentiment_scores\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error analyzing sentiment for headline '{headline[:50]}...': {e}\", exc_info=True)\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "# Trading Signal Generation Function (from subtask 5)\n",
        "def generate_trading_signal(technical_data: pd.DataFrame, sentiment_scores: dict) -> str:\n",
        "    \"\"\"\n",
        "    Generates a trading signal based on technical and sentiment analysis with logging and error handling.\n",
        "    \"\"\"\n",
        "    if not isinstance(technical_data, pd.DataFrame) or technical_data.empty:\n",
        "        logger.warning(\"Technical data input to generate_trading_signal is not a valid pandas DataFrame or is empty.\")\n",
        "        return 'UNDETERMINED'\n",
        "    if not isinstance(sentiment_scores, dict) or 'compound' not in sentiment_scores:\n",
        "        logger.warning(\"Sentiment scores input to generate_trading_signal is not a valid dictionary or is missing 'compound' score.\")\n",
        "        return 'UNDETERMINED'\n",
        "\n",
        "    required_tech_cols = ['RSI_14', 'MACD_12_26_9', 'MACDH_12_26_9', 'MACDS_12_26_9', 'SMA_20', 'SMA_50', 'Close']\n",
        "    if not all(col in technical_data.columns for col in required_tech_cols):\n",
        "        logger.error(f\"Technical data DataFrame must contain the following columns for signal generation: {required_tech_cols}\")\n",
        "        return 'UNDETERMINED'\n",
        "\n",
        "    try:\n",
        "        logger.info(\"Generating trading signal...\")\n",
        "        latest_data = technical_data.iloc[-1]\n",
        "        sentiment_compound_score = sentiment_scores.get('compound', 0)\n",
        "\n",
        "        tech_buy_signal = False\n",
        "        tech_sell_signal = False\n",
        "\n",
        "        # Technical Analysis Rules (with checks for sufficient data)\n",
        "        if technical_data.shape[0] >= 2:\n",
        "            # Golden Cross\n",
        "            if technical_data['SMA_20'].iloc[-2] <= technical_data['SMA_50'].iloc[-2] and latest_data['SMA_20'] > latest_data['SMA_50']:\n",
        "                tech_buy_signal = True\n",
        "                logger.debug(\"Technical BUY signal: Golden Cross detected.\")\n",
        "            # RSI oversold and turning up\n",
        "            if latest_data['RSI_14'] < 30 and technical_data['RSI_14'].iloc[-2] <= latest_data['RSI_14']:\n",
        "                 tech_buy_signal = True\n",
        "                 logger.debug(\"Technical BUY signal: RSI oversold and turning up.\")\n",
        "            # MACD Crossover (MACD above Signal)\n",
        "            if technical_data['MACD_12_26_9'].iloc[-2] <= technical_data['MACDS_12_26_9'].iloc[-2] and latest_data['MACD_12_26_9'] > latest_data['MACDS_12_26_9']:\n",
        "                 tech_buy_signal = True\n",
        "                 logger.debug(\"Technical BUY signal: MACD crossover detected.\")\n",
        "\n",
        "            # Death Cross\n",
        "            if technical_data['SMA_20'].iloc[-2] >= technical_data['SMA_50'].iloc[-2] and latest_data['SMA_20'] < latest_data['SMA_50']:\n",
        "                tech_sell_signal = True\n",
        "                logger.debug(\"Technical SELL signal: Death Cross detected.\")\n",
        "            # RSI overbought and turning down\n",
        "            if latest_data['RSI_14'] > 70 and technical_data['RSI_14'].iloc[-2] >= latest_data['RSI_14']:\n",
        "                 tech_sell_signal = True\n",
        "                 logger.debug(\"Technical SELL signal: RSI overbought and turning down.\")\n",
        "            # MACD Crossover (MACD below Signal)\n",
        "            if technical_data['MACD_12_26_9'].iloc[-2] >= technical_data['MACDS_12_26_9'].iloc[-2] and latest_data['MACD_12_26_9'] < latest_data['MACDS_12_26_9']:\n",
        "                 tech_sell_signal = True\n",
        "                 logger.debug(\"Technical SELL signal: MACD crossover detected.\")\n",
        "        else:\n",
        "             logger.warning(\"Insufficient data points for technical analysis rules requiring lookback.\")\n",
        "\n",
        "\n",
        "        # Sentiment Analysis Rule\n",
        "        sentiment_positive = sentiment_compound_score > 0.1\n",
        "        sentiment_negative = sentiment_compound_score < -0.1\n",
        "\n",
        "        # Combine Technical and Sentiment Analysis\n",
        "        signal = 'HOLD'\n",
        "        if tech_buy_signal and sentiment_positive:\n",
        "            signal = 'BUY'\n",
        "            logger.info(\"Generated BUY signal based on technical and positive sentiment.\")\n",
        "        elif tech_sell_signal and sentiment_negative:\n",
        "            signal = 'SELL'\n",
        "            logger.info(\"Generated SELL signal based on technical and negative sentiment.\")\n",
        "        elif tech_buy_signal and not sentiment_negative:\n",
        "            signal = 'BUY'\n",
        "            logger.info(\"Generated BUY signal based on technical and non-negative sentiment.\")\n",
        "        elif tech_sell_signal and not sentiment_positive:\n",
        "            signal = 'SELL'\n",
        "            logger.info(\"Generated SELL signal based on technical and non-positive sentiment.\")\n",
        "        else:\n",
        "            logger.info(\"Generated HOLD signal.\")\n",
        "\n",
        "        return signal\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating trading signal: {e}\", exc_info=True)\n",
        "        return 'UNDETERMINED'\n",
        "\n",
        "# Risk Management Functions (from subtask 6)\n",
        "def calculate_position_size(total_capital: float, risk_percentage: float, stop_loss_price: float, entry_price: float) -> float:\n",
        "    \"\"\"\n",
        "    Calculates suggested position size with logging and error handling.\n",
        "    \"\"\"\n",
        "    logger.info(f\"Calculating position size for capital={total_capital}, risk_pct={risk_percentage}, stop_loss={stop_loss_price}, entry={entry_price}\")\n",
        "    if not isinstance(total_capital, (int, float)) or total_capital <= 0:\n",
        "        logger.error(\"Error: Total capital must be a positive number.\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "    if not isinstance(risk_percentage, (int, float)) or not 0 < risk_percentage <= 1:\n",
        "        logger.error(\"Error: Risk percentage must be between 0 (exclusive) and 1 (inclusive).\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "    if not isinstance(stop_loss_price, (int, float)) or stop_loss_price <= 0:\n",
        "        logger.error(\"Error: Stop-loss price must be a positive number.\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "    if not isinstance(entry_price, (int, float)) or entry_price <= 0:\n",
        "        logger.error(\"Error: Entry price must be a positive number.\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "    risk_per_share = abs(entry_price - stop_loss_price)\n",
        "\n",
        "    if risk_per_share <= 0:\n",
        "        logger.error(\"Error: Risk per share is zero or negative. Cannot calculate position size.\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "    try:\n",
        "        risk_amount = total_capital * risk_percentage\n",
        "        suggested_shares = risk_amount / risk_per_share\n",
        "        logger.info(f\"Calculated suggested shares: {suggested_shares}\")\n",
        "        return suggested_shares\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error calculating position size: {e}\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "\n",
        "def calculate_stop_loss(entry_price: float, risk_tolerance: float, is_long: bool = True) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the suggested stop-loss price with logging and error handling.\n",
        "    \"\"\"\n",
        "    logger.info(f\"Calculating stop-loss for entry={entry_price}, risk_tolerance={risk_tolerance}, is_long={is_long}\")\n",
        "    if not isinstance(entry_price, (int, float)) or entry_price <= 0:\n",
        "        logger.error(\"Error: Entry price must be a positive number for stop-loss calculation.\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "    if not isinstance(risk_tolerance, (int, float)) or risk_tolerance < 0:\n",
        "        logger.error(\"Error: Risk tolerance must be a non-negative number for stop-loss calculation.\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "    try:\n",
        "        if is_long:\n",
        "            if 0 < risk_tolerance < 1:\n",
        "                 stop_loss = entry_price * (1 - risk_tolerance)\n",
        "            else:\n",
        "                 stop_loss = entry_price - risk_tolerance\n",
        "        else:\n",
        "            if 0 < risk_tolerance < 1:\n",
        "                 stop_loss = entry_price * (1 + risk_tolerance)\n",
        "            else:\n",
        "                 stop_loss = entry_price + risk_tolerance\n",
        "\n",
        "        logger.info(f\"Calculated stop-loss: {stop_loss}\")\n",
        "        return stop_loss\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error calculating stop-loss: {e}\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "\n",
        "def calculate_target_profit(entry_price: float, target_profit_factor: float, is_long: bool = True) -> float:\n",
        "    \"\"\"\n",
        "    Calculates the suggested target profit price with logging and error handling.\n",
        "    \"\"\"\n",
        "    logger.info(f\"Calculating target profit for entry={entry_price}, target_profit_factor={target_profit_factor}, is_long={is_long}\")\n",
        "    if not isinstance(entry_price, (int, float)) or entry_price <= 0:\n",
        "        logger.error(\"Error: Entry price must be a positive number for target profit calculation.\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "    if not isinstance(target_profit_factor, (int, float)) or target_profit_factor <= 0:\n",
        "        logger.error(\"Error: Target profit factor must be a positive number for target profit calculation.\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "    try:\n",
        "        if is_long:\n",
        "            target_profit = entry_price * (1 + target_profit_factor)\n",
        "        else:\n",
        "            target_profit = entry_price * (1 - target_profit_factor)\n",
        "\n",
        "        logger.info(f\"Calculated target profit: {target_profit}\")\n",
        "        return target_profit\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error calculating target profit: {e}\", exc_info=True)\n",
        "        return 0\n",
        "\n",
        "# Trading Infrastructure Functions (from subtask 7 & 8)\n",
        "# Note: These functions depend on the successful import of alpaca_trade_api,\n",
        "# which has failed in previous steps. Logging is added assuming the import\n",
        "# would eventually succeed.\n",
        "def initialize_alpaca_api() -> tradeapi.REST:\n",
        "    \"\"\"\n",
        "    Initializes and returns an Alpaca API object with logging and error handling.\n",
        "    \"\"\"\n",
        "    if tradeapi is None:\n",
        "        logger.error(\"Alpaca API library not imported. Cannot initialize API.\")\n",
        "        return None\n",
        "\n",
        "    api_key_id = os.getenv('APCA_API_KEY_ID')\n",
        "    api_secret_key = os.getenv('APCA_API_SECRET_KEY')\n",
        "    base_url = os.getenv('APCA_API_BASE_URL', 'https://paper-api.alpaca.markets')\n",
        "\n",
        "    if not api_key_id or not api_secret_key:\n",
        "        logger.error(\"Alpaca API keys (APCA_API_KEY_ID and APCA_API_SECRET_KEY) not found in environment variables. Cannot initialize API.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        logger.info(f\"Attempting to initialize Alpaca API with base URL: {base_url}\")\n",
        "        api = tradeapi.REST(api_key_id, api_secret_key, base_url, api_version='v2')\n",
        "        logger.info(\"Alpaca API object initialized successfully.\")\n",
        "        return api\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error initializing Alpaca API: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "def check_alpaca_connection(api: tradeapi.REST) -> bool:\n",
        "    \"\"\"\n",
        "    Checks the status of the Alpaca API connection with logging and error handling.\n",
        "    \"\"\"\n",
        "    if api is None:\n",
        "        logger.warning(\"Alpaca API object is not initialized. Cannot check connection.\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        logger.info(\"Checking Alpaca API connection...\")\n",
        "        account = api.get_account()\n",
        "        logger.info(f\"Alpaca API connection successful. Account Status: {account.status}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error checking Alpaca API connection: {e}\", exc_info=True)\n",
        "        return False\n",
        "\n",
        "# Real-time Data Handling Function (from subtask 9)\n",
        "async def connect_finnhub_websocket(api_key: str, symbols: list):\n",
        "    \"\"\"\n",
        "    Connects to the Finnhub WebSocket and subscribes to real-time trade data with logging and error handling.\n",
        "    \"\"\"\n",
        "    if not api_key:\n",
        "        logger.error(\"Finnhub API key is not provided for WebSocket connection.\")\n",
        "        return\n",
        "\n",
        "    uri = f\"wss://ws.finnhub.io?token={api_key}\"\n",
        "    logger.info(f\"Attempting to connect to Finnhub WebSocket at {uri}\")\n",
        "\n",
        "    try:\n",
        "        async with websockets.connect(uri) as websocket:\n",
        "            logger.info(\"Finnhub WebSocket connection established.\")\n",
        "\n",
        "            for symbol in symbols:\n",
        "                subscribe_message = {\"type\": \"subscribe\", \"symbol\": symbol}\n",
        "                await websocket.send(json.dumps(subscribe_message))\n",
        "                logger.info(f\"Sent WebSocket subscription request for {symbol}\")\n",
        "\n",
        "            while True:\n",
        "                try:\n",
        "                    message = await websocket.recv()\n",
        "                    # Process the received message (currently just logs it)\n",
        "                    logger.debug(f\"Received WebSocket message: {message}\") # Use debug level for frequent messages\n",
        "\n",
        "                    # Example parsing (uncomment and expand as needed)\n",
        "                    # data = json.loads(message)\n",
        "                    # if data.get('type') == 'trade':\n",
        "                    #     logger.info(f\"Received trade data for {data.get('data')[0].get('s')}: {data.get('data')[0].get('p')}\")\n",
        "                    # elif data.get('type') == 'ping':\n",
        "                    #      await websocket.send('{\"type\":\"pong\"}')\n",
        "                    #      logger.debug(\"Sent WebSocket pong response.\")\n",
        "\n",
        "\n",
        "                except websockets.exceptions.ConnectionClosedOK:\n",
        "                    logger.info(\"Finnhub WebSocket connection closed normally.\")\n",
        "                    break\n",
        "                except Exception as e:\n",
        "                    logger.error(f\"Error receiving or processing WebSocket message: {e}\", exc_info=True)\n",
        "                    break\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error connecting to Finnhub WebSocket: {e}\", exc_info=True)\n",
        "\n",
        "print(\"Logging and error handling added to functions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15e9ffa9"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code block failed because the type hint `-> tradeapi.REST` caused an `AttributeError` when `tradeapi` was None due to the failed import in a previous step. To fix this, I will remove the type hint from the function signature. The rest of the function definitions with logging and error handling can remain the same.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LEUMJqrEPjn6"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Configure logging (already configured, but include for context)\n",
        "# Ensure the logs directory exists\n",
        "if not os.path.exists('logs'):\n",
        "    os.makedirs('logs')\n",
        "\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    handlers=[\n",
        "        logging.FileHandler(\"logs/apexammo.log\"),\n",
        "        logging.StreamHandler(sys.stdout)\n",
        "    ]\n",
        ")\n",
        "\n",
        "logger = logging.getLogger('ApexAMMO')\n",
        "\n",
        "# Modify previously defined functions to include logging and enhanced error handling\n",
        "# The functions from previous subtasks were already modified in the last attempt.\n",
        "# We only need to redefine the Alpaca functions to remove the problematic type hint.\n",
        "\n",
        "# Trading Infrastructure Functions (from subtask 7 & 8)\n",
        "# Note: These functions depend on the successful import of alpaca_trade_api,\n",
        "# which has failed in previous steps. Logging is added assuming the import\n",
        "# would eventually succeed.\n",
        "# Removed type hint -> tradeapi.REST\n",
        "def initialize_alpaca_api():\n",
        "    \"\"\"\n",
        "    Initializes and returns an Alpaca API object with logging and error handling.\n",
        "    \"\"\"\n",
        "    if tradeapi is None:\n",
        "        logger.error(\"Alpaca API library not imported. Cannot initialize API.\")\n",
        "        return None\n",
        "\n",
        "    api_key_id = os.getenv('APCA_API_KEY_ID')\n",
        "    api_secret_key = os.getenv('APCA_API_SECRET_KEY')\n",
        "    base_url = os.getenv('APCA_API_BASE_URL', 'https://paper-api.alpaca.markets')\n",
        "\n",
        "    if not api_key_id or not api_secret_key:\n",
        "        logger.error(\"Alpaca API keys (APCA_API_KEY_ID and APCA_API_SECRET_KEY) not found in environment variables. Cannot initialize API.\")\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        logger.info(f\"Attempting to initialize Alpaca API with base URL: {base_url}\")\n",
        "        api = tradeapi.REST(api_key_id, api_secret_key, base_url, api_version='v2')\n",
        "        logger.info(\"Alpaca API object initialized successfully.\")\n",
        "        return api\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error initializing Alpaca API: {e}\", exc_info=True)\n",
        "        return None\n",
        "\n",
        "# Removed type hint api: tradeapi.REST\n",
        "def check_alpaca_connection(api):\n",
        "    \"\"\"\n",
        "    Checks the status of the Alpaca API connection with logging and error handling.\n",
        "    \"\"\"\n",
        "    if api is None:\n",
        "        logger.warning(\"Alpaca API object is not initialized. Cannot check connection.\")\n",
        "        return False\n",
        "\n",
        "    try:\n",
        "        logger.info(\"Checking Alpaca API connection...\")\n",
        "        # This line might still cause an AttributeError if `api` is not a valid Alpaca API object\n",
        "        # due to the import failure, but the function definition itself will succeed.\n",
        "        account = api.get_account()\n",
        "        logger.info(f\"Alpaca API connection successful. Account Status: {account.status}\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        # Catching general Exception here to handle potential AttributeError on `api.get_account()`\n",
        "        logger.error(f\"Error checking Alpaca API connection: {e}\", exc_info=True)\n",
        "        return False\n",
        "\n",
        "# The other functions (fetch_historical_data, fetch_realtime_data, fetch_news_headlines,\n",
        "# calculate_technical_indicators, determine_market_personality, analyze_sentiment,\n",
        "# generate_trading_signal, calculate_position_size, calculate_stop_loss,\n",
        "# calculate_target_profit, connect_finnhub_websocket) already had logging and error\n",
        "# handling added and do not need to be redefined unless there are specific\n",
        "# issues with their implementation. The previous error was specific to the Alpaca type hints.\n",
        "\n",
        "\n",
        "print(\"Alpaca API functions redefined without type hints to avoid AttributeError.\")\n",
        "print(\"Logging and error handling for other functions were already added in the previous attempt.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cf1b995b"
      },
      "source": [
        "## Combine rule-based and predictive strategies\n",
        "\n",
        "### Subtask:\n",
        "Integrate both rule-based trading strategies and the predictive models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a1c1af3"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the main trading decision function that integrates rule-based signals and ML predictions, following the outlined steps to combine signals and handle missing predictions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5c2eaa66"
      },
      "outputs": [],
      "source": [
        "def make_trading_decision(technical_data: pd.DataFrame, sentiment_scores: dict, ml_prediction: str = None) -> str:\n",
        "    \"\"\"\n",
        "    Combines rule-based trading signals and ML model predictions to make a final trading decision.\n",
        "\n",
        "    Args:\n",
        "        technical_data: DataFrame containing historical stock data with calculated\n",
        "                        technical indicators (e.g., RSI, MACD, SMA).\n",
        "        sentiment_scores: A dictionary containing sentiment scores, likely\n",
        "                          including a 'compound' score.\n",
        "        ml_prediction: The prediction from the machine learning model ('Up', 'Down', or None).\n",
        "\n",
        "    Returns:\n",
        "        A string representing the final combined trading signal ('BUY', 'SELL', 'HOLD', 'UNDETERMINED').\n",
        "    \"\"\"\n",
        "    logger.info(\"Making trading decision...\")\n",
        "\n",
        "    # 1. Get the rule-based signal\n",
        "    rule_based_signal = generate_trading_signal(technical_data, sentiment_scores)\n",
        "    logger.info(f\"Rule-based signal: {rule_based_signal}\")\n",
        "\n",
        "    final_signal = 'UNDETERMINED' # Default signal\n",
        "\n",
        "    # 3. & 4. Incorporate ML prediction and define combination rules\n",
        "    if ml_prediction is None:\n",
        "        logger.warning(\"ML prediction not available. Relying solely on rule-based signal.\")\n",
        "        final_signal = rule_based_signal\n",
        "    else:\n",
        "        logger.info(f\"ML prediction available: {ml_prediction}\")\n",
        "        # Example Rules for combining signals:\n",
        "\n",
        "        # Strong BUY signal if rule-based is BUY and ML predicts Up\n",
        "        if rule_based_signal == 'BUY' and ml_prediction == 'Up':\n",
        "            final_signal = 'BUY'\n",
        "        # Strong SELL signal if rule-based is SELL and ML predicts Down\n",
        "        elif rule_based_signal == 'SELL' and ml_prediction == 'Down':\n",
        "            final_signal = 'SELL'\n",
        "        # BUY signal if rule-based is HOLD but ML strongly predicts Up\n",
        "        # (Need a way to represent \"strongly predicts\" - for simplicity, assume ML prediction 'Up' is strong enough here)\n",
        "        elif rule_based_signal == 'HOLD' and ml_prediction == 'Up':\n",
        "            final_signal = 'BUY'\n",
        "        # SELL signal if rule-based is HOLD but ML strongly predicts Down\n",
        "        elif rule_based_signal == 'HOLD' and ml_prediction == 'Down':\n",
        "            final_signal = 'SELL'\n",
        "        # BUY signal if rule-based is UNDETERMINED but ML predicts Up\n",
        "        elif rule_based_signal == 'UNDETERMINED' and ml_prediction == 'Up':\n",
        "             final_signal = 'BUY'\n",
        "        # SELL signal if rule-based is UNDETERMINED but ML predicts Down\n",
        "        elif rule_based_signal == 'UNDETERMINED' and ml_prediction == 'Down':\n",
        "             final_signal = 'SELL'\n",
        "        # Default to HOLD if rules don't result in BUY/SELL or if ML prediction contradicts rule-based signal\n",
        "        else:\n",
        "            final_signal = 'HOLD'\n",
        "            logger.info(\"ML prediction contradicts rule-based signal or rules are not met. Defaulting to HOLD.\")\n",
        "\n",
        "\n",
        "    logger.info(f\"Final combined trading signal: {final_signal}\")\n",
        "    return final_signal\n",
        "\n",
        "# Example Usage (requires dummy data for technical_data and sentiment_scores)\n",
        "# Assuming dummy_tech_df and dummy_sentiment are available from the previous subtask examples\n",
        "\n",
        "# Example 1: Rule-based BUY, ML predicts Up\n",
        "# dummy_tech_df_buy = pd.DataFrame({\n",
        "#     'Open': [100, 101, 102, 103, 104], 'High': [102, 103, 104, 105, 106], 'Low': [99, 100, 101, 102, 103],\n",
        "#     'Close': [101, 102, 103, 104, 105], 'Volume': [1000, 1100, 1050, 1200, 1150],\n",
        "#     'RSI_14': [40, 45, 50, 55, 60], 'MACD_12_26_9': [1, 1.5, 2, 2.5, 3], 'MACDH_12_26_9': [0.1, 0.2, 0.3, 0.4, 0.5],\n",
        "#     'MACDS_12_26_9': [0.9, 1.3, 1.7, 2.1, 2.5], 'SMA_20': [100.5, 101.2, 102.1, 103.0, 104.0],\n",
        "#     'SMA_50': [99.0, 99.5, 100.0, 100.5, 101.0]\n",
        "# })\n",
        "# dummy_sentiment_positive = {'neg': 0.1, 'neu': 0.7, 'pos': 0.2, 'compound': 0.3}\n",
        "# ml_pred_up = 'Up'\n",
        "# decision1 = make_trading_decision(dummy_tech_df_buy, dummy_sentiment_positive, ml_pred_up)\n",
        "# print(f\"\\nDecision 1: {decision1}\") # Expected: BUY\n",
        "\n",
        "# Example 2: Rule-based SELL, ML predicts Down\n",
        "# dummy_tech_df_sell = pd.DataFrame({\n",
        "#     'Open': [105, 104, 103, 102, 101], 'High': [106, 105, 104, 103, 102], 'Low': [104, 103, 102, 101, 100],\n",
        "#     'Close': [104, 103, 102, 101, 100], 'Volume': [1100, 1200, 1150, 1300, 1250],\n",
        "#     'RSI_14': [60, 55, 50, 45, 40], 'MACD_12_26_9': [3, 2.5, 2, 1.5, 1], 'MACDH_12_26_9': [0.5, 0.4, 0.3, 0.2, 0.1],\n",
        "#     'MACDS_12_26_9': [2.5, 2.1, 1.7, 1.3, 0.9], 'SMA_20': [104.0, 103.0, 102.1, 101.2, 100.5],\n",
        "#     'SMA_50': [101.0, 100.5, 100.0, 99.5, 99.0]\n",
        "# })\n",
        "# dummy_sentiment_negative = {'neg': 0.4, 'neu': 0.5, 'pos': 0.1, 'compound': -0.2}\n",
        "# ml_pred_down = 'Down'\n",
        "# decision2 = make_trading_decision(dummy_tech_df_sell, dummy_sentiment_negative, ml_pred_down)\n",
        "# print(f\"\\nDecision 2: {decision2}\") # Expected: SELL\n",
        "\n",
        "# Example 3: Rule-based HOLD, ML predicts Up\n",
        "# dummy_tech_df_hold = pd.DataFrame({\n",
        "#     'Open': [100, 100.5, 101, 100.8, 101.2], 'High': [101, 101.5, 102, 101.8, 102.2], 'Low': [99, 99.5, 100, 99.8, 100.2],\n",
        "#     'Close': [100.5, 101, 100.8, 101.2, 101.5], 'Volume': [1000, 950, 1020, 980, 1050],\n",
        "#     'RSI_14': [48, 52, 51, 53, 55], 'MACD_12_26_9': [0.5, 0.6, 0.55, 0.62, 0.65], 'MACDH_12_26_9': [0.1, 0.15, 0.1, 0.12, 0.15],\n",
        "#     'MACDS_12_26_9': [0.4, 0.45, 0.45, 0.5, 0.5], 'SMA_20': [100.8, 100.9, 101.0, 101.1, 101.2],\n",
        "#     'SMA_50': [100.0, 100.1, 100.2, 100.3, 100.4]\n",
        "# })\n",
        "# dummy_sentiment_neutral = {'neg': 0.2, 'neu': 0.6, 'pos': 0.2, 'compound': 0.05}\n",
        "# ml_pred_up = 'Up'\n",
        "# decision3 = make_trading_decision(dummy_tech_df_hold, dummy_sentiment_neutral, ml_pred_up)\n",
        "# print(f\"\\nDecision 3: {decision3}\") # Expected: BUY\n",
        "\n",
        "# Example 4: Rule-based BUY, ML predicts Down (Contradiction)\n",
        "# decision4 = make_trading_decision(dummy_tech_df_buy, dummy_sentiment_positive, 'Down')\n",
        "# print(f\"\\nDecision 4: {decision4}\") # Expected: HOLD (based on example rule)\n",
        "\n",
        "# Example 5: Rule-based BUY, ML prediction is None\n",
        "# decision5 = make_trading_decision(dummy_tech_df_buy, dummy_sentiment_positive, None)\n",
        "# print(f\"\\nDecision 5: {decision5}\") # Expected: BUY (rely on rule-based)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7826e254"
      },
      "source": [
        "## Testing and backtesting\n",
        "\n",
        "### Subtask:\n",
        "Develop procedures for testing the agent's components and backtesting trading strategies using historical data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e25d7cf8"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the `run_backtest` function to simulate trades and calculate performance metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "58a481fd"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger('ApexAMMO')\n",
        "\n",
        "def run_backtest(historical_data: pd.DataFrame, trading_strategy_func, initial_capital: float = 100000, risk_percentage: float = 0.01, risk_reward_ratio: float = 2.0) -> tuple:\n",
        "    \"\"\"\n",
        "    Runs a backtest of a trading strategy using historical data.\n",
        "\n",
        "    Args:\n",
        "        historical_data: DataFrame containing historical stock data with technical indicators.\n",
        "                         Must include 'Close' and any indicators required by the strategy function.\n",
        "        trading_strategy_func: A function that takes a slice of historical_data,\n",
        "                               sentiment_scores (can be dummy or None for backtesting),\n",
        "                               and optionally ml_prediction (can be dummy or None)\n",
        "                               and returns a trading signal ('BUY', 'SELL', 'HOLD', 'UNDETERMINED').\n",
        "        initial_capital: The starting capital for the backtest.\n",
        "        risk_percentage: Percentage of total capital to risk per trade (as a decimal).\n",
        "        risk_reward_ratio: The desired risk/reward ratio for target profit calculation.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "        - backtest_results (dict): Dictionary of key backtesting metrics.\n",
        "        - trades_log (list): A list of dictionaries, each representing a simulated trade.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting backtest...\")\n",
        "\n",
        "    if not isinstance(historical_data, pd.DataFrame) or historical_data.empty:\n",
        "        logger.error(\"Historical data input is not a valid pandas DataFrame or is empty.\")\n",
        "        return {}, []\n",
        "\n",
        "    capital = initial_capital\n",
        "    position = 0  # Number of shares held\n",
        "    entry_price = 0 # Price at which position was entered\n",
        "    in_position = False\n",
        "    trades_log = []\n",
        "    portfolio_value = [] # To track portfolio value over time\n",
        "\n",
        "    # Ensure historical_data is sorted by index (assumed to be date/time)\n",
        "    historical_data = historical_data.sort_index()\n",
        "\n",
        "    # Simulate day by day or bar by bar\n",
        "    for i in range(len(historical_data)):\n",
        "        current_day_data = historical_data.iloc[:i+1] # Data up to the current day\n",
        "        current_price = current_day_data['Close'].iloc[-1]\n",
        "        current_date = current_day_data.index[-1]\n",
        "\n",
        "        # Append current portfolio value (capital + value of position)\n",
        "        portfolio_value.append({'date': current_date, 'value': capital + (position * current_price)})\n",
        "\n",
        "        # Skip if not enough data for indicators/strategy\n",
        "        if len(current_day_data) < 50: # Example: requires at least 50 data points for SMA_50\n",
        "             logger.debug(f\"Skipping day {current_date}: Not enough data for indicators ({len(current_day_data)}).\")\n",
        "             continue\n",
        "\n",
        "        # Get trading signal for the current day based on data up to this point\n",
        "        # For backtesting, we might not have real sentiment or future ML predictions,\n",
        "        # so we pass dummy values or None.\n",
        "        # Assuming trading_strategy_func can handle None for sentiment and ml_prediction\n",
        "        try:\n",
        "            # Pass only the data available up to the current point in the backtest\n",
        "            # Ensure the strategy function can handle a DataFrame slice\n",
        "            signal = trading_strategy_func(current_day_data, sentiment_scores=None, ml_prediction=None)\n",
        "            logger.debug(f\"Date: {current_date}, Price: {current_price}, Signal: {signal}, In Position: {in_position}\")\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating signal for date {current_date}: {e}\", exc_info=True)\n",
        "            signal = 'UNDETERMINED' # Default to HOLD on error\n",
        "\n",
        "\n",
        "        # Execute trades based on the signal and current position\n",
        "        if signal == 'BUY' and not in_position:\n",
        "            # Calculate position size and stop-loss\n",
        "            # For backtesting, we need to calculate SL based on historical data context\n",
        "            # A simple approach: SL based on a percentage below current price\n",
        "            # A more advanced approach would use ATR or recent low/high\n",
        "            risk_tolerance_value = current_price * (risk_percentage * risk_reward_ratio) # Example: Use R/R to define a price distance for SL calculation\n",
        "            stop_loss_price = calculate_stop_loss(current_price, risk_tolerance_value, is_long=True)\n",
        "\n",
        "            # Ensure stop_loss_price is valid and below current price\n",
        "            if stop_loss_price <= 0 or stop_loss_price >= current_price:\n",
        "                 logger.warning(f\"Date: {current_date}, Invalid calculated stop-loss price {stop_loss_price}. Cannot enter position.\")\n",
        "                 continue # Skip trade if SL is invalid\n",
        "\n",
        "            # Calculate suggested shares based on the calculated stop-loss price\n",
        "            suggested_shares = calculate_position_size(capital, risk_percentage, stop_loss_price, current_price)\n",
        "\n",
        "            if suggested_shares > 0:\n",
        "                shares_to_buy = int(suggested_shares) # Buy whole shares\n",
        "                cost = shares_to_buy * current_price\n",
        "\n",
        "                if cost <= capital:\n",
        "                    capital -= cost\n",
        "                    position = shares_to_buy\n",
        "                    entry_price = current_price\n",
        "                    in_position = True\n",
        "                    trade = {\n",
        "                        'date': current_date,\n",
        "                        'type': 'BUY',\n",
        "                        'price': current_price,\n",
        "                        'shares': shares_to_buy,\n",
        "                        'capital_after_trade': capital,\n",
        "                        'position_after_trade': position,\n",
        "                        'stop_loss': stop_loss_price # Record SL at entry\n",
        "                    }\n",
        "                    trades_log.append(trade)\n",
        "                    logger.info(f\"Date: {current_date}, Executed BUY {shares_to_buy} shares at {current_price}. Capital: {capital}, Position: {position}\")\n",
        "                else:\n",
        "                    logger.warning(f\"Date: {current_date}, Not enough capital to buy {shares_to_buy} shares at {current_price}. Required: {cost}, Available: {capital}\")\n",
        "            else:\n",
        "                 logger.warning(f\"Date: {current_date}, Suggested shares to buy is 0 or less based on position size calculation.\")\n",
        "\n",
        "\n",
        "        elif signal == 'SELL' and in_position:\n",
        "            # Simulate selling the entire position\n",
        "            revenue = position * current_price\n",
        "            profit_loss = (current_price - entry_price) * position\n",
        "            capital += revenue\n",
        "            trade = {\n",
        "                'date': current_date,\n",
        "                'type': 'SELL',\n",
        "                'price': current_price,\n",
        "                'shares': position,\n",
        "                'profit_loss': profit_loss,\n",
        "                'capital_after_trade': capital,\n",
        "                'position_after_trade': 0\n",
        "            }\n",
        "            trades_log.append(trade)\n",
        "            logger.info(f\"Date: {current_date}, Executed SELL {position} shares at {current_price}. Profit/Loss: {profit_loss}. Capital: {capital}, Position: 0\")\n",
        "            position = 0\n",
        "            entry_price = 0\n",
        "            in_position = False\n",
        "\n",
        "        # Implement stop-loss logic (check if current price hits stop-loss)\n",
        "        # This needs to be checked even if the signal is not SELL\n",
        "        if in_position and stop_loss_price > 0: # Ensure stop-loss was set\n",
        "            if (position > 0 and current_price <= stop_loss_price) or \\\n",
        "               (position < 0 and current_price >= stop_loss_price): # For short positions if implemented later\n",
        "                 # Simulate stop-loss triggered\n",
        "                 revenue = abs(position) * current_price\n",
        "                 profit_loss = (current_price - entry_price) * position # Profit/Loss calculation for long\n",
        "                 capital += revenue\n",
        "                 logger.warning(f\"Date: {current_date}, Stop-loss triggered at {current_price}. Exiting position.\")\n",
        "                 trade = {\n",
        "                     'date': current_date,\n",
        "                     'type': 'STOP_LOSS_SELL' if position > 0 else 'STOP_LOSS_BUY_TO_COVER',\n",
        "                     'price': current_price,\n",
        "                     'shares': abs(position),\n",
        "                     'profit_loss': profit_loss,\n",
        "                     'capital_after_trade': capital,\n",
        "                     'position_after_trade': 0,\n",
        "                     'triggered_by': 'stop_loss'\n",
        "                 }\n",
        "                 trades_log.append(trade)\n",
        "                 position = 0\n",
        "                 entry_price = 0\n",
        "                 in_position = False\n",
        "\n",
        "        # Implement target profit logic (check if current price hits target profit)\n",
        "        # This needs to be checked even if the signal is not SELL\n",
        "        # Calculate target profit based on entry price and risk/reward\n",
        "        if in_position and entry_price > 0 and stop_loss_price > 0:\n",
        "            risk_per_share = abs(entry_price - stop_loss_price)\n",
        "            target_profit_price = entry_price + (risk_per_share * risk_reward_ratio) # For long position\n",
        "\n",
        "            if (position > 0 and current_price >= target_profit_price): # For long position\n",
        "                 # Simulate target profit reached\n",
        "                 revenue = abs(position) * current_price\n",
        "                 profit_loss = (current_price - entry_price) * position # Profit/Loss calculation for long\n",
        "                 capital += revenue\n",
        "                 logger.info(f\"Date: {current_date}, Target profit reached at {current_price}. Exiting position.\")\n",
        "                 trade = {\n",
        "                     'date': current_date,\n",
        "                     'type': 'TARGET_PROFIT_SELL' if position > 0 else 'TARGET_PROFIT_BUY_TO_COVER',\n",
        "                     'price': current_price,\n",
        "                     'shares': abs(position),\n",
        "                     'profit_loss': profit_loss,\n",
        "                     'capital_after_trade': capital,\n",
        "                     'position_after_trade': 0,\n",
        "                     'triggered_by': 'target_profit'\n",
        "                 }\n",
        "                 trades_log.append(trade)\n",
        "                 position = 0\n",
        "                 entry_price = 0\n",
        "                 in_position = False\n",
        "\n",
        "\n",
        "    # After the loop, if still in position, close the position at the last price\n",
        "    if in_position:\n",
        "        last_price = historical_data['Close'].iloc[-1]\n",
        "        revenue = position * last_price\n",
        "        profit_loss = (last_price - entry_price) * position\n",
        "        capital += revenue\n",
        "        logger.info(f\"End of backtest. Exiting final position of {position} shares at {last_price}. Profit/Loss: {profit_loss}.\")\n",
        "        trade = {\n",
        "            'date': historical_data.index[-1],\n",
        "            'type': 'END_OF_BACKTEST_SELL' if position > 0 else 'END_OF_BACKTEST_BUY_TO_COVER',\n",
        "            'price': last_price,\n",
        "            'shares': position,\n",
        "            'profit_loss': profit_loss,\n",
        "            'capital_after_trade': capital,\n",
        "            'position_after_trade': 0,\n",
        "            'triggered_by': 'end_of_backtest'\n",
        "        }\n",
        "        trades_log.append(trade)\n",
        "        position = 0\n",
        "\n",
        "\n",
        "    # Calculate key backtesting metrics\n",
        "    total_profit_loss = capital - initial_capital\n",
        "    num_trades = len([t for t in trades_log if t['type'] in ['SELL', 'STOP_LOSS_SELL', 'TARGET_PROFIT_SELL', 'END_OF_BACKTEST_SELL']]) # Count closing trades\n",
        "\n",
        "    winning_trades = [t for t in trades_log if 'profit_loss' in t and t['profit_loss'] > 0]\n",
        "    losing_trades = [t for t in trades_log if 'profit_loss' in t and t['profit_loss'] <= 0] # Include zero profit/loss as non-winning\n",
        "\n",
        "    num_winning_trades = len(winning_trades)\n",
        "    num_losing_trades = len(losing_trades)\n",
        "    total_closed_trades = num_winning_trades + num_losing_trades\n",
        "\n",
        "    win_rate = (num_winning_trades / total_closed_trades) * 100 if total_closed_trades > 0 else 0\n",
        "\n",
        "    average_profit_per_trade = sum(t['profit_loss'] for t in winning_trades) / num_winning_trades if num_winning_trades > 0 else 0\n",
        "    average_loss_per_trade = sum(t['profit_loss'] for t in losing_trades) / num_losing_trades if num_losing_trades > 0 else 0\n",
        "    average_profit_loss_per_trade = total_profit_loss / total_closed_trades if total_closed_trades > 0 else 0\n",
        "\n",
        "    # Calculate Max Drawdown\n",
        "    portfolio_df = pd.DataFrame(portfolio_value)\n",
        "    if not portfolio_df.empty:\n",
        "        portfolio_df['peak'] = portfolio_df['value'].cummax()\n",
        "        portfolio_df['drawdown'] = portfolio_df['value'] - portfolio_df['peak']\n",
        "        max_drawdown = portfolio_df['drawdown'].min() if not portfolio_df['drawdown'].empty else 0\n",
        "    else:\n",
        "        max_drawdown = 0\n",
        "\n",
        "\n",
        "    backtest_results = {\n",
        "        'initial_capital': initial_capital,\n",
        "        'final_capital': capital,\n",
        "        'total_profit_loss': total_profit_loss,\n",
        "        'return_percentage': (total_profit_loss / initial_capital) * 100 if initial_capital > 0 else 0,\n",
        "        'num_trades': num_trades,\n",
        "        'num_winning_trades': num_winning_trades,\n",
        "        'num_losing_trades': num_losing_trades,\n",
        "        'win_rate (%)': win_rate,\n",
        "        'average_profit_per_trade': average_profit_per_trade,\n",
        "        'average_loss_per_trade': average_loss_per_trade,\n",
        "        'average_profit_loss_per_trade': average_profit_loss_per_trade,\n",
        "        'max_drawdown': max_drawdown,\n",
        "        'sharpe_ratio': 'N/A' # Placeholder - requires more data/complexity\n",
        "        # Add other relevant metrics\n",
        "    }\n",
        "\n",
        "    logger.info(\"Backtest completed.\")\n",
        "    return backtest_results, trades_log\n",
        "\n",
        "# Assuming calculate_position_size, calculate_stop_loss, and generate_trading_signal\n",
        "# are defined in previous steps.\n",
        "\n",
        "# Example Usage (requires a dummy or actual historical_data DataFrame and the trading_strategy_func)\n",
        "# Assuming 'historical_data' DataFrame is available and has 'Close' column,\n",
        "# and 'generate_trading_signal' and risk management functions are defined.\n",
        "\n",
        "# Create a dummy historical_data DataFrame for backtesting example\n",
        "# (This should ideally come from the data acquisition step and have indicators added)\n",
        "if 'historical_data' not in locals() or historical_data.empty:\n",
        "    print(\"Using dummy historical data for backtest example.\")\n",
        "    data = {\n",
        "        'Open': np.random.rand(100) * 100 + 50,\n",
        "        'High': np.random.rand(100) * 100 + 55,\n",
        "        'Low': np.random.rand(100) * 100 + 45,\n",
        "        'Close': np.random.rand(100) * 100 + 50,\n",
        "        'Volume': np.random.rand(100) * 1000000\n",
        "    }\n",
        "    index = pd.date_range(start='2023-01-01', periods=100, freq='D')\n",
        "    historical_data = pd.DataFrame(data, index=index)\n",
        "\n",
        "    # Add dummy technical indicators (for demonstration purposes)\n",
        "    historical_data['RSI_14'] = np.random.rand(100) * 50 + 25\n",
        "    historical_data['MACD_12_26_9'] = np.random.rand(100) * 5 - 2.5\n",
        "    historical_data['MACDH_12_26_9'] = np.random.rand(100) * 2 - 1\n",
        "    historical_data['MACDS_12_26_9'] = np.random.rand(100) * 4 - 2\n",
        "    historical_data['SMA_20'] = historical_data['Close'].rolling(window=20).mean().fillna(0)\n",
        "    historical_data['SMA_50'] = historical_data['Close'].rolling(window=50).mean().fillna(0)\n",
        "\n",
        "\n",
        "# Example of a simple trading strategy function (replace with your actual strategy)\n",
        "# This is a placeholder to make the run_backtest function runnable\n",
        "def example_trading_strategy(data: pd.DataFrame, sentiment_scores: dict = None, ml_prediction: str = None) -> str:\n",
        "    \"\"\"A simple placeholder trading strategy.\"\"\"\n",
        "    if len(data) < 50: # Ensure enough data for basic indicators\n",
        "        return 'UNDETERMINED'\n",
        "\n",
        "    latest_data = data.iloc[-1]\n",
        "\n",
        "    # Simple rule: Buy if SMA_20 > SMA_50 and Close > SMA_20\n",
        "    if latest_data['SMA_20'] > latest_data['SMA_50'] and latest_data['Close'] > latest_data['SMA_20']:\n",
        "        return 'BUY'\n",
        "    # Simple rule: Sell if SMA_20 < SMA_50 and Close < SMA_20\n",
        "    elif latest_data['SMA_20'] < latest_data['SMA_50'] and latest_data['Close'] < latest_data['SMA_20']:\n",
        "        return 'SELL'\n",
        "    else:\n",
        "        return 'HOLD'\n",
        "\n",
        "# Run the backtest with the dummy data and example strategy\n",
        "# backtest_results, trades_log = run_backtest(historical_data.copy(), example_trading_strategy, initial_capital=100000)\n",
        "\n",
        "# print(\"\\nBacktest Results:\")\n",
        "# display(backtest_results)\n",
        "\n",
        "# print(\"\\nTrades Log (first 5 trades):\")\n",
        "# display(trades_log[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "479eaff5"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the `test_component` function to test individual components of the agent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c4a5cfe9"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "logger = logging.getLogger('ApexAMMO')\n",
        "\n",
        "def test_component(component_func, input_data, expected_output=None):\n",
        "    \"\"\"\n",
        "    Tests a specific component function with sample input data.\n",
        "\n",
        "    Args:\n",
        "        component_func: The function to be tested.\n",
        "        input_data: Sample input data for the component function.\n",
        "        expected_output: Optional. The expected output or a criteria for validating the output.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the test results (success, actual_output, expected_output, message).\n",
        "    \"\"\"\n",
        "    logger.info(f\"Testing component: {component_func.__name__}...\")\n",
        "    results = {\n",
        "        'component': component_func.__name__,\n",
        "        'success': False,\n",
        "        'actual_output': None,\n",
        "        'expected_output': expected_output,\n",
        "        'message': ''\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        actual_output = component_func(input_data)\n",
        "        results['actual_output'] = actual_output\n",
        "        logger.info(f\"Component {component_func.__name__} executed successfully.\")\n",
        "\n",
        "        if expected_output is not None:\n",
        "            # Basic validation: check if actual output matches expected output\n",
        "            # More complex validation logic can be added here based on component type\n",
        "            if actual_output == expected_output:\n",
        "                results['success'] = True\n",
        "                results['message'] = \"Output matches expected output.\"\n",
        "                logger.info(f\"Test passed for {component_func.__name__}: Output matches expected.\")\n",
        "            else:\n",
        "                results['success'] = False\n",
        "                results['message'] = f\"Output mismatch. Expected: {expected_output}, Got: {actual_output}\"\n",
        "                logger.warning(f\"Test failed for {component_func.__name__}: Output mismatch.\")\n",
        "        else:\n",
        "            # If no expected_output is provided, consider execution without error as success\n",
        "            results['success'] = True\n",
        "            results['message'] = \"Component executed without errors.\"\n",
        "            logger.info(f\"Test passed for {component_func.__name__}: Executed without errors.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        results['success'] = False\n",
        "        results['message'] = f\"Error executing component: {e}\"\n",
        "        logger.error(f\"Error testing component {component_func.__name__}: {e}\", exc_info=True)\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example Usage (requires a sample component function and input data)\n",
        "\n",
        "# Assuming analyze_sentiment function is defined from a previous step\n",
        "# from nltk.sentiment.vader import SentimentIntensityAnalyzer # Import if not already available\n",
        "\n",
        "# Create dummy data for testing\n",
        "# headline1 = \"Apple stock rose significantly today.\"\n",
        "# expected_sentiment1 = {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.6486} # Expected from VADER\n",
        "\n",
        "# Test the analyze_sentiment component\n",
        "# if 'analyze_sentiment' in locals():\n",
        "#     sentiment_test_results = test_component(analyze_sentiment, headline1, expected_sentiment1)\n",
        "#     print(\"\\nSentiment Component Test Results:\")\n",
        "#     display(sentiment_test_results)\n",
        "# else:\n",
        "#     print(\"\\n'analyze_sentiment' function not found. Skipping component test example.\")\n",
        "\n",
        "# Example of testing a function that returns a calculated value\n",
        "# Assuming calculate_position_size function is defined from a previous step\n",
        "# from risk_management import calculate_position_size # Import if not already available\n",
        "\n",
        "# total_capital = 10000\n",
        "# risk_percentage = 0.01\n",
        "# stop_loss_price = 49.5\n",
        "# entry_price = 50.0\n",
        "# expected_shares = (total_capital * risk_percentage) / abs(entry_price - stop_loss_price) # Expected calculation\n",
        "\n",
        "# Test the calculate_position_size component\n",
        "# if 'calculate_position_size' in locals():\n",
        "#     position_size_test_results = test_component(calculate_position_size,\n",
        "#                                                {'total_capital': total_capital, 'risk_percentage': risk_percentage,\n",
        "#                                                 'stop_loss_price': stop_loss_price, 'entry_price': entry_price},\n",
        "#                                                expected_shares)\n",
        "#     # Note: test_component expects input_data to be directly passed to the function.\n",
        "#     # For functions with multiple arguments, you might need a wrapper function\n",
        "#     # or modify test_component to accept args/kwargs.\n",
        "#     # For this example, we'll test with a simple function or a wrapper.\n",
        "\n",
        "#     # Example wrapper for calculate_position_size\n",
        "#     # def calculate_position_size_wrapper(data):\n",
        "#     #    return calculate_position_size(data['total_capital'], data['risk_percentage'], data['stop_loss_price'], data['entry_price'])\n",
        "\n",
        "#     # position_size_test_results = test_component(calculate_position_size_wrapper,\n",
        "#     #                                           {'total_capital': total_capital, 'risk_percentage': risk_percentage,\n",
        "#     #                                            'stop_loss_price': stop_loss_price, 'entry_price': entry_price},\n",
        "#     #                                           expected_shares)\n",
        "\n",
        "#     # print(\"\\nPosition Size Component Test Results:\")\n",
        "#     # display(position_size_test_results)\n",
        "# else:\n",
        "#     print(\"\\n'calculate_position_size' function not found. Skipping component test example.\")\n",
        "\n",
        "print(\"Function 'test_component' defined.\")\n",
        "print(\"Example usage is commented out.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6oTm0qo87FwYIElTSEbSR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}